{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mainly looking at https://github.com/ngessert/isic2019/blob/master/models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRFX': 'Mel0629A1',\n",
       " 'PRFX_B4': 'Mel0627D1',\n",
       " 'FLD2USE_B4': 0,\n",
       " 'PRFX_PREP': 'MelPrp0628B1',\n",
       " 'ARCH': 'efficientnet-b1',\n",
       " 'SZ': 224,\n",
       " 'EPOCHS': 100,\n",
       " 'BS': 96,\n",
       " 'K': 5,\n",
       " 'SEED': 101,\n",
       " 'FLD2USE': 0,\n",
       " 'FP16': True,\n",
       " 'PLTFACTOR': 0.5,\n",
       " 'PATIENCE': 5,\n",
       " 'MIN_LR': 1e-08,\n",
       " 'LR': 0.001,\n",
       " 'WD': 0.001,\n",
       " 'N_SAMPL': None,\n",
       " 'DEBUG': False}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Param: pass\n",
    "param = Param()\n",
    "\n",
    "#########################\n",
    "param.PRFX = 'Mel0629A1'#\n",
    "#########################\n",
    "\n",
    "param.PRFX_B4 = 'Mel0627D1'; param.FLD2USE_B4 = 0\n",
    "param.PRFX_PREP = 'MelPrp0628B1'\n",
    "param.ARCH = 'efficientnet-b1'\n",
    "param.SZ = 224\n",
    "param.EPOCHS = 100\n",
    "\n",
    "# p2: efficientnet-b1 64\n",
    "param.BS = 96\n",
    "\n",
    "param.K=5; param.SEED=101; param.FLD2USE=0\n",
    "param.FP16 = True\n",
    "param.PLTFACTOR=0.5; param.PATIENCE=5; param.MIN_LR=1e-8\n",
    "\n",
    "param.LR=1e-3\n",
    "param.WD=1e-3\n",
    "\n",
    "param.N_SAMPL = None\n",
    "\n",
    "param.DEBUG = False\n",
    "if param.DEBUG: \n",
    "    param.EPOCHS = 5\n",
    "    param.K = 5\n",
    "    param.N_SAMPL = 2048\n",
    "\n",
    "DEVICE = 'cuda'; PIN_MEM = (DEVICE=='cuda'); N_WORKERS=4\n",
    "\n",
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 29 19:20:23 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   43C    P0    34W / 300W |     11MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os, sys, gc\n",
    "import datetime\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score as roc_auc\n",
    "\n",
    "# https://github.com/eriklindernoren/PyTorch-YOLOv3/issues/162#issuecomment-491115265\n",
    "from PIL import ImageFile; ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "import torch\n",
    "device=torch.device(DEVICE)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "set_seed(param.SEED)\n",
    "\n",
    "\n",
    "\n",
    "p_out = f'../output/{param.PRFX}'; Path(p_out).mkdir(exist_ok=True,parents=True)\n",
    "p_cmp = '../input/siim-isic-melanoma-classification'\n",
    "p_b4  = f'../output/{param.PRFX_B4}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58457, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>im_pth</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24437</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0628B1/siim-isic-melanoma-clas...</td>\n",
       "      <td>IP_4021847</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57432</th>\n",
       "      <td>19</td>\n",
       "      <td>../output/MelPrp0628B1/andrewmvd--isic-2019/IS...</td>\n",
       "      <td>BCN_0004730</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                             im_pth   patient_id  \\\n",
       "24437      20  ../output/MelPrp0628B1/siim-isic-melanoma-clas...   IP_4021847   \n",
       "57432      19  ../output/MelPrp0628B1/andrewmvd--isic-2019/IS...  BCN_0004730   \n",
       "\n",
       "       target  \n",
       "24437     0.0  \n",
       "57432     1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(58457, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    33126\n",
       "19    25331\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "19    0.178516\n",
       "20    0.017630\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_prp = f'../output/{param.PRFX_PREP}'\n",
    "dftrn = pd.read_csv(f'{p_prp}/train_all.csv') \n",
    "print(dftrn.shape)\n",
    "\n",
    "set_seed(param.SEED); dftrn = dftrn.sample(frac=1.)\n",
    "\n",
    "if param.N_SAMPL is not None: dftrn = dftrn.head(param.N_SAMPL)\n",
    "    \n",
    "display(dftrn.head(2))\n",
    "display(dftrn.shape)\n",
    "display(dftrn.source.value_counts())\n",
    "display(dftrn.groupby('source').target.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/mel/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "idx_nopid=np.where(dftrn.patient_id.isna())[0]\n",
    "print(len(idx_nopid))\n",
    "dftrn['patient_id'].iloc[idx_nopid]=[f'Nan_{i}' for i in range(len(idx_nopid))]\n",
    "assert dftrn.patient_id.isna().mean()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 46765 11692\n",
      "1 46765 11692\n",
      "2 46766 11691\n",
      "3 46766 11691\n",
      "4 46766 11691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.913953\n",
       "1.0    0.086047\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.911066\n",
       "1.0    0.088934\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.915173\n",
       "1.0    0.084827\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.91218\n",
       "1.0    0.08782\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.910897\n",
       "1.0    0.089103\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26536\n",
       "19    20229\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26644\n",
       "19    20121\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26529\n",
       "19    20237\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26491\n",
       "19    20275\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26304\n",
       "19    20462\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(param.SEED)\n",
    "kf = GroupKFold(n_splits=param.K)\n",
    "fld2trvl={fld:(tr,vl) for fld,(tr,vl) in enumerate(kf.split(dftrn, groups=dftrn.patient_id))}\n",
    "\n",
    "for fld, (tr, vl) in fld2trvl.items():\n",
    "    print(fld, len(tr), len(vl))\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    dfvl=dftrn.iloc[vl]\n",
    "    assert set(dftr.patient_id)&set(dfvl.patient_id)==set()\n",
    "for fld, (tr, vl) in fld2trvl.items():\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    display(dftr.target.value_counts()/len(tr))\n",
    "for fld, (tr, vl) in fld2trvl.items():\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    display(dftr.source.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(Dataset):\n",
    "    def __init__(self, df, istrn=True):\n",
    "        self.df = df\n",
    "        self.istrn = istrn\n",
    "        self.composed = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(param.SZ),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])    \n",
    "    def __getitem__(self, i):\n",
    "        x = Image.open(self.df.im_pth.values[i]) \n",
    "        x = self.composed(x)\n",
    "        if self.istrn:\n",
    "            y = self.df.target.values[i]\n",
    "            return x, y\n",
    "        else:\n",
    "            return (x,)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkmdl():  \n",
    "    mdl = EfficientNet.from_pretrained(param.ARCH, num_classes=1)\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdl = mkmdl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    prd = []\n",
    "    y = []\n",
    "    for step, dat in enumerate(dl):\n",
    "        xb, yb = (o.to(device) for o in dat)\n",
    "        with torch.no_grad(): prdb = model(xb)\n",
    "        prd.append(prdb.cpu().detach().numpy())\n",
    "        y.append(yb.cpu().detach().numpy())\n",
    "    prd = np.concatenate(prd)    \n",
    "    y = np.concatenate(y)    \n",
    "    lss = F.binary_cross_entropy_with_logits(torch.tensor(prd),torch.tensor(y).unsqueeze(1)).item()\n",
    "    scr = roc_auc(y, prd)\n",
    "    return lss, scr, y, prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n",
      "load previously trained ../output/Mel0627D1/model_Mel0627D1_fld_0_best.p\n"
     ]
    }
   ],
   "source": [
    "mdl = mkmdl()\n",
    "mdl = mdl.to(device)\n",
    "\n",
    "if param.PRFX_B4 is not None: \n",
    "    fnm_mdl_b4 = f'{p_b4}/model_{param.PRFX_B4}_fld_{param.FLD2USE_B4}_best.p'\n",
    "    print('load previously trained', fnm_mdl_b4)\n",
    "    mdl.load_state_dict(torch.load(fnm_mdl_b4, map_location=torch.device(DEVICE)))\n",
    "\n",
    "\n",
    "# opt = optim.SGD(mdl.parameters(), lr=param.LR, momentum=param.MOMENTUM, weight_decay=param.WD)\n",
    "opt = optim.Adam(mdl.parameters(), lr=param.LR, weight_decay=param.WD)\n",
    "schdl = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=param.PLTFACTOR, patience=param.PATIENCE, min_lr=param.MIN_LR, verbose=True)\n",
    "if param.FP16: mdl, opt = amp.initialize(mdl, opt, opt_level='O1', verbosity=0)\n",
    "mdl.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46765 11692\n",
      "46765 11692\n",
      "488 61\n"
     ]
    }
   ],
   "source": [
    "tr,vl=fld2trvl[param.FLD2USE]\n",
    "dftr=dftrn.iloc[tr]\n",
    "dfvl=dftrn.iloc[vl]\n",
    "ystr=dftr.target.values\n",
    "ysvl=dfvl.target.values\n",
    "print(len(dftr), len(dfvl))\n",
    "dstr = MelDataset(dftr)\n",
    "dsvl = MelDataset(dfvl)\n",
    "print(len(dstr), len(dsvl))\n",
    "dltr = DataLoader(dstr, batch_size=param.BS,   shuffle=True,  num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "dlvl = DataLoader(dsvl, batch_size=param.BS*2, shuffle=False, num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "print(len(dltr), len(dlvl))\n",
    "lendl=len(dltr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['fld2trvl'] = fld2trvl\n",
    "results['param'] = param\n",
    "\n",
    "stats = {\n",
    "    'lss': {'tr':[],'vl':[]},\n",
    "    'scr': {'tr':[],'vl':[]},\n",
    "}\n",
    "oof = {'y':[], 'prd':[]}\n",
    "\n",
    "\n",
    "def save_results():\n",
    "    results['oof'] = oof\n",
    "    stats['best_scr'] = best_scr\n",
    "    stats['best_epc'] = best_epc\n",
    "    results['stats'] = stats\n",
    "    pickle.dump(results, open(f'{p_out}/results_{param.PRFX}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-29 19:20:48 ep 0 step 0/488\n",
      "2020-06-29 19:28:50 ep 0: lss_tr 0.226; lss_vl 0.296; scr_tr 0.840; scr_vl 0.857; \n",
      "better scr -inf -> 0.857\n",
      "2020-06-29 19:28:53 ep 1 step 0/488\n",
      "2020-06-29 19:36:31 ep 1: lss_tr 0.224; lss_vl 0.235; scr_tr 0.844; scr_vl 0.863; \n",
      "better scr 0.857 -> 0.863\n",
      "2020-06-29 19:36:37 ep 2 step 0/488\n",
      "2020-06-29 19:46:46 ep 2: lss_tr 0.226; lss_vl 0.225; scr_tr 0.839; scr_vl 0.863; \n",
      "better scr 0.863 -> 0.863\n",
      "2020-06-29 19:46:52 ep 3 step 0/488\n",
      "2020-06-29 19:55:53 ep 3: lss_tr 0.225; lss_vl 0.235; scr_tr 0.842; scr_vl 0.852; \n",
      "2020-06-29 19:55:57 ep 4 step 0/488\n",
      "2020-06-29 20:02:44 ep 4: lss_tr 0.225; lss_vl 0.238; scr_tr 0.842; scr_vl 0.861; \n",
      "2020-06-29 20:02:47 ep 5 step 0/488\n",
      "2020-06-29 20:09:40 ep 5: lss_tr 0.225; lss_vl 0.230; scr_tr 0.841; scr_vl 0.858; \n",
      "2020-06-29 20:09:44 ep 6 step 0/488\n",
      "2020-06-29 20:16:35 ep 6: lss_tr 0.226; lss_vl 0.257; scr_tr 0.840; scr_vl 0.860; \n",
      "2020-06-29 20:16:39 ep 7 step 0/488\n",
      "2020-06-29 20:23:11 ep 7: lss_tr 0.225; lss_vl 0.238; scr_tr 0.840; scr_vl 0.850; \n",
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-04.\n",
      "2020-06-29 20:23:14 ep 8 step 0/488\n",
      "2020-06-29 20:29:41 ep 8: lss_tr 0.224; lss_vl 0.230; scr_tr 0.844; scr_vl 0.858; \n",
      "2020-06-29 20:29:45 ep 9 step 0/488\n",
      "2020-06-29 20:36:15 ep 9: lss_tr 0.221; lss_vl 0.232; scr_tr 0.850; scr_vl 0.863; \n",
      "better scr 0.863 -> 0.863\n",
      "2020-06-29 20:36:18 ep 10 step 0/488\n",
      "2020-06-29 20:42:44 ep 10: lss_tr 0.223; lss_vl 0.224; scr_tr 0.845; scr_vl 0.861; \n",
      "2020-06-29 20:42:46 ep 11 step 0/488\n",
      "2020-06-29 20:49:13 ep 11: lss_tr 0.222; lss_vl 0.224; scr_tr 0.847; scr_vl 0.863; \n",
      "2020-06-29 20:49:16 ep 12 step 0/488\n",
      "2020-06-29 20:55:38 ep 12: lss_tr 0.222; lss_vl 0.224; scr_tr 0.848; scr_vl 0.860; \n",
      "2020-06-29 20:55:41 ep 13 step 0/488\n",
      "2020-06-29 21:02:19 ep 13: lss_tr 0.222; lss_vl 0.225; scr_tr 0.849; scr_vl 0.866; \n",
      "better scr 0.863 -> 0.866\n",
      "2020-06-29 21:02:22 ep 14 step 0/488\n",
      "2020-06-29 21:09:08 ep 14: lss_tr 0.223; lss_vl 0.231; scr_tr 0.847; scr_vl 0.861; \n",
      "2020-06-29 21:09:12 ep 15 step 0/488\n",
      "2020-06-29 21:15:44 ep 15: lss_tr 0.222; lss_vl 0.234; scr_tr 0.848; scr_vl 0.862; \n",
      "2020-06-29 21:15:47 ep 16 step 0/488\n",
      "2020-06-29 21:22:21 ep 16: lss_tr 0.223; lss_vl 0.232; scr_tr 0.844; scr_vl 0.864; \n",
      "2020-06-29 21:22:24 ep 17 step 0/488\n",
      "2020-06-29 21:29:09 ep 17: lss_tr 0.222; lss_vl 0.241; scr_tr 0.847; scr_vl 0.862; \n",
      "2020-06-29 21:29:12 ep 18 step 0/488\n",
      "2020-06-29 21:35:39 ep 18: lss_tr 0.222; lss_vl 0.237; scr_tr 0.847; scr_vl 0.861; \n",
      "2020-06-29 21:35:42 ep 19 step 0/488\n",
      "2020-06-29 21:42:06 ep 19: lss_tr 0.222; lss_vl 0.236; scr_tr 0.847; scr_vl 0.855; \n",
      "Epoch    20: reducing learning rate of group 0 to 2.5000e-04.\n",
      "2020-06-29 21:42:09 ep 20 step 0/488\n",
      "2020-06-29 21:48:42 ep 20: lss_tr 0.222; lss_vl 0.221; scr_tr 0.848; scr_vl 0.865; \n",
      "2020-06-29 21:48:45 ep 21 step 0/488\n",
      "2020-06-29 21:55:13 ep 21: lss_tr 0.220; lss_vl 0.230; scr_tr 0.851; scr_vl 0.862; \n",
      "2020-06-29 21:55:15 ep 22 step 0/488\n",
      "2020-06-29 22:01:38 ep 22: lss_tr 0.221; lss_vl 0.223; scr_tr 0.850; scr_vl 0.864; \n",
      "2020-06-29 22:01:41 ep 23 step 0/488\n",
      "2020-06-29 22:08:09 ep 23: lss_tr 0.223; lss_vl 0.223; scr_tr 0.846; scr_vl 0.861; \n",
      "2020-06-29 22:08:12 ep 24 step 0/488\n",
      "2020-06-29 22:14:34 ep 24: lss_tr 0.221; lss_vl 0.223; scr_tr 0.849; scr_vl 0.863; \n",
      "2020-06-29 22:14:37 ep 25 step 0/488\n",
      "2020-06-29 22:21:00 ep 25: lss_tr 0.221; lss_vl 0.225; scr_tr 0.850; scr_vl 0.863; \n",
      "Epoch    26: reducing learning rate of group 0 to 1.2500e-04.\n",
      "2020-06-29 22:21:03 ep 26 step 0/488\n",
      "2020-06-29 22:27:27 ep 26: lss_tr 0.221; lss_vl 0.223; scr_tr 0.850; scr_vl 0.861; \n",
      "2020-06-29 22:27:30 ep 27 step 0/488\n",
      "2020-06-29 22:34:00 ep 27: lss_tr 0.220; lss_vl 0.220; scr_tr 0.853; scr_vl 0.866; \n",
      "2020-06-29 22:34:03 ep 28 step 0/488\n",
      "2020-06-29 22:40:29 ep 28: lss_tr 0.220; lss_vl 0.225; scr_tr 0.851; scr_vl 0.867; \n",
      "better scr 0.866 -> 0.867\n",
      "2020-06-29 22:40:32 ep 29 step 0/488\n",
      "2020-06-29 22:46:58 ep 29: lss_tr 0.220; lss_vl 0.221; scr_tr 0.851; scr_vl 0.868; \n",
      "better scr 0.867 -> 0.868\n",
      "2020-06-29 22:47:01 ep 30 step 0/488\n",
      "2020-06-29 22:53:29 ep 30: lss_tr 0.219; lss_vl 0.221; scr_tr 0.854; scr_vl 0.863; \n",
      "2020-06-29 22:53:33 ep 31 step 0/488\n",
      "2020-06-29 22:59:56 ep 31: lss_tr 0.219; lss_vl 0.226; scr_tr 0.854; scr_vl 0.869; \n",
      "better scr 0.868 -> 0.869\n",
      "2020-06-29 22:59:59 ep 32 step 0/488\n",
      "2020-06-29 23:06:25 ep 32: lss_tr 0.220; lss_vl 0.224; scr_tr 0.852; scr_vl 0.865; \n",
      "2020-06-29 23:06:28 ep 33 step 0/488\n",
      "2020-06-29 23:13:01 ep 33: lss_tr 0.221; lss_vl 0.222; scr_tr 0.850; scr_vl 0.867; \n",
      "2020-06-29 23:13:05 ep 34 step 0/488\n",
      "2020-06-29 23:19:28 ep 34: lss_tr 0.220; lss_vl 0.222; scr_tr 0.851; scr_vl 0.862; \n",
      "2020-06-29 23:19:31 ep 35 step 0/488\n",
      "2020-06-29 23:25:52 ep 35: lss_tr 0.219; lss_vl 0.222; scr_tr 0.854; scr_vl 0.870; \n",
      "better scr 0.869 -> 0.870\n",
      "2020-06-29 23:25:55 ep 36 step 0/488\n",
      "2020-06-29 23:32:22 ep 36: lss_tr 0.220; lss_vl 0.220; scr_tr 0.853; scr_vl 0.868; \n",
      "2020-06-29 23:32:25 ep 37 step 0/488\n",
      "2020-06-29 23:38:53 ep 37: lss_tr 0.221; lss_vl 0.222; scr_tr 0.851; scr_vl 0.863; \n",
      "2020-06-29 23:38:56 ep 38 step 0/488\n",
      "2020-06-29 23:45:30 ep 38: lss_tr 0.219; lss_vl 0.228; scr_tr 0.854; scr_vl 0.862; \n",
      "2020-06-29 23:45:33 ep 39 step 0/488\n",
      "2020-06-29 23:51:59 ep 39: lss_tr 0.219; lss_vl 0.220; scr_tr 0.853; scr_vl 0.867; \n",
      "2020-06-29 23:52:02 ep 40 step 0/488\n",
      "2020-06-29 23:58:32 ep 40: lss_tr 0.220; lss_vl 0.222; scr_tr 0.851; scr_vl 0.864; \n",
      "2020-06-29 23:58:35 ep 41 step 0/488\n",
      "2020-06-30 00:05:01 ep 41: lss_tr 0.220; lss_vl 0.223; scr_tr 0.851; scr_vl 0.862; \n",
      "Epoch    42: reducing learning rate of group 0 to 6.2500e-05.\n",
      "2020-06-30 00:05:04 ep 42 step 0/488\n",
      "2020-06-30 00:11:30 ep 42: lss_tr 0.220; lss_vl 0.218; scr_tr 0.851; scr_vl 0.869; \n",
      "2020-06-30 00:11:32 ep 43 step 0/488\n",
      "2020-06-30 00:17:52 ep 43: lss_tr 0.219; lss_vl 0.220; scr_tr 0.853; scr_vl 0.868; \n",
      "2020-06-30 00:17:55 ep 44 step 0/488\n",
      "2020-06-30 00:24:19 ep 44: lss_tr 0.219; lss_vl 0.223; scr_tr 0.853; scr_vl 0.866; \n",
      "2020-06-30 00:24:21 ep 45 step 0/488\n",
      "2020-06-30 00:30:49 ep 45: lss_tr 0.219; lss_vl 0.219; scr_tr 0.854; scr_vl 0.870; \n",
      "better scr 0.870 -> 0.870\n",
      "2020-06-30 00:30:52 ep 46 step 0/488\n",
      "2020-06-30 00:37:15 ep 46: lss_tr 0.220; lss_vl 0.220; scr_tr 0.852; scr_vl 0.866; \n",
      "2020-06-30 00:37:18 ep 47 step 0/488\n",
      "2020-06-30 00:43:44 ep 47: lss_tr 0.218; lss_vl 0.217; scr_tr 0.856; scr_vl 0.873; \n",
      "better scr 0.870 -> 0.873\n",
      "2020-06-30 00:43:47 ep 48 step 0/488\n",
      "2020-06-30 00:50:11 ep 48: lss_tr 0.220; lss_vl 0.223; scr_tr 0.852; scr_vl 0.866; \n",
      "2020-06-30 00:50:14 ep 49 step 0/488\n",
      "2020-06-30 00:56:40 ep 49: lss_tr 0.218; lss_vl 0.219; scr_tr 0.855; scr_vl 0.868; \n",
      "2020-06-30 00:56:43 ep 50 step 0/488\n",
      "2020-06-30 01:03:07 ep 50: lss_tr 0.218; lss_vl 0.219; scr_tr 0.855; scr_vl 0.868; \n",
      "2020-06-30 01:03:10 ep 51 step 0/488\n",
      "2020-06-30 01:09:39 ep 51: lss_tr 0.219; lss_vl 0.222; scr_tr 0.854; scr_vl 0.863; \n",
      "2020-06-30 01:09:42 ep 52 step 0/488\n",
      "2020-06-30 01:16:20 ep 52: lss_tr 0.219; lss_vl 0.220; scr_tr 0.853; scr_vl 0.867; \n",
      "2020-06-30 01:16:23 ep 53 step 0/488\n",
      "2020-06-30 01:24:27 ep 53: lss_tr 0.219; lss_vl 0.220; scr_tr 0.854; scr_vl 0.868; \n",
      "Epoch    54: reducing learning rate of group 0 to 3.1250e-05.\n",
      "2020-06-30 01:24:30 ep 54 step 0/488\n",
      "2020-06-30 01:30:57 ep 54: lss_tr 0.219; lss_vl 0.217; scr_tr 0.854; scr_vl 0.871; \n",
      "2020-06-30 01:31:00 ep 55 step 0/488\n",
      "2020-06-30 01:37:28 ep 55: lss_tr 0.220; lss_vl 0.223; scr_tr 0.853; scr_vl 0.864; \n",
      "2020-06-30 01:37:31 ep 56 step 0/488\n",
      "2020-06-30 01:43:55 ep 56: lss_tr 0.218; lss_vl 0.219; scr_tr 0.855; scr_vl 0.868; \n",
      "2020-06-30 01:43:57 ep 57 step 0/488\n",
      "2020-06-30 01:50:27 ep 57: lss_tr 0.218; lss_vl 0.220; scr_tr 0.856; scr_vl 0.869; \n",
      "2020-06-30 01:50:30 ep 58 step 0/488\n",
      "2020-06-30 01:56:55 ep 58: lss_tr 0.219; lss_vl 0.221; scr_tr 0.854; scr_vl 0.868; \n",
      "2020-06-30 01:56:58 ep 59 step 0/488\n",
      "2020-06-30 02:03:25 ep 59: lss_tr 0.218; lss_vl 0.218; scr_tr 0.855; scr_vl 0.870; \n",
      "Epoch    60: reducing learning rate of group 0 to 1.5625e-05.\n",
      "2020-06-30 02:03:28 ep 60 step 0/488\n",
      "2020-06-30 02:09:58 ep 60: lss_tr 0.219; lss_vl 0.218; scr_tr 0.853; scr_vl 0.872; \n",
      "2020-06-30 02:10:01 ep 61 step 0/488\n",
      "2020-06-30 02:16:32 ep 61: lss_tr 0.221; lss_vl 0.219; scr_tr 0.850; scr_vl 0.870; \n",
      "2020-06-30 02:16:36 ep 62 step 0/488\n",
      "2020-06-30 02:23:06 ep 62: lss_tr 0.219; lss_vl 0.218; scr_tr 0.855; scr_vl 0.871; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-30 02:23:09 ep 63 step 0/488\n",
      "2020-06-30 02:29:47 ep 63: lss_tr 0.219; lss_vl 0.220; scr_tr 0.854; scr_vl 0.867; \n",
      "2020-06-30 02:29:50 ep 64 step 0/488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/anaconda3/envs/mel/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/data/anaconda3/envs/mel/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/data/anaconda3/envs/mel/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/data/anaconda3/envs/mel/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fc608c765521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFP16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/mel/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/mel/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_scr = float('-inf')\n",
    "best_epc = -1\n",
    "for epc in range(param.EPOCHS):\n",
    "    prdtr_ep=[]\n",
    "    ytr_ep=[]\n",
    "    for step, dat in enumerate(dltr):\n",
    "        mdl.train()\n",
    "        xb,yb=(o.to(device) for o in dat)\n",
    "        yb = yb.unsqueeze(1)\n",
    "        prdb = mdl(xb)\n",
    "        loss = F.binary_cross_entropy_with_logits(prdb, yb)\n",
    "        if param.FP16:\n",
    "            with amp.scale_loss(loss, opt) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        if param.FP16:\n",
    "            torch.nn.utils.clip_grad_norm_(amp.master_params(opt), 1)\n",
    "        else:\n",
    "            torch.nn.utils.clip_grad_norm_(mdl.parameters(), 1)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        prdtr_ep.append(prdb.cpu().detach().numpy())\n",
    "        ytr_ep.append(yb.cpu().detach().numpy())\n",
    "        if step>0 and step%1000==0: print(dtnow(), f'ep {epc} step {step}/{lendl}')\n",
    "    \n",
    "    prdtr_ep = np.concatenate(prdtr_ep)\n",
    "    ytr_ep = np.concatenate(ytr_ep)    \n",
    "    lss_tr_ep = F.binary_cross_entropy_with_logits(torch.tensor(prdtr_ep),torch.tensor(ytr_ep)).item()\n",
    "    scr_tr_ep = roc_auc(ytr_ep, prdtr_ep)\n",
    "    stats['lss']['tr'].append(lss_tr_ep)\n",
    "    stats['scr']['tr'].append(scr_tr_ep)\n",
    "    \n",
    "    lss_vl_ep, scr_vl_ep, yvl_ep, prdvl_ep = evaluate(mdl, dlvl)\n",
    "    stats['lss']['vl'].append(lss_vl_ep)\n",
    "    stats['scr']['vl'].append(scr_vl_ep)\n",
    "    oof['y'].append(yvl_ep)\n",
    "    oof['prd'].append(prdvl_ep)\n",
    "    \n",
    "    print(dtnow(), f'ep {epc}: lss_tr {lss_tr_ep:.3f}; lss_vl {lss_vl_ep:.3f}; scr_tr {scr_tr_ep:.3f}; scr_vl {scr_vl_ep:.3f}; ')\n",
    "    \n",
    "    if scr_vl_ep>best_scr:\n",
    "        print(f'better scr {best_scr:.3f} -> {scr_vl_ep:.3f}')\n",
    "        best_scr = scr_vl_ep\n",
    "        best_epc = epc\n",
    "        torch.save(mdl.state_dict(), f'{p_out}/model_{param.PRFX}_fld_{param.FLD2USE}_best.p')\n",
    "    if not param.DEBUG: torch.save(mdl.state_dict(), f'{p_out}/model_{param.PRFX}_fld_{param.FLD2USE}_epc_{epc}.p')\n",
    "        \n",
    "    schdl.step(scr_vl_ep)  # Update learning rate schedule\n",
    "    save_results()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'best_scr {best_scr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(stats['lss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(stats['scr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mtrc in ['lss', 'scr']:\n",
    "    recs=stats[mtrc]\n",
    "    for tv,vs in recs.items():\n",
    "        plt.title(f'{mtrc} {tv}')\n",
    "        plt.plot(vs, 'o--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftst = pd.read_csv(f'{p_prp}/test.csv', nrows=128 if param.DEBUG else None) \n",
    "display(dftst.head(3))\n",
    "\n",
    "dfsub = pd.read_csv(f'{p_cmp}/sample_submission.csv', nrows=128 if param.DEBUG else None) \n",
    "\n",
    "dstst = MelDataset(dftst, istrn=False)\n",
    "print(len(dstst))\n",
    "dltst = DataLoader(dstst, batch_size=param.BS*2, shuffle=False, num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "print(len(dltst))\n",
    "lendl=len(dltst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = mkmdl()\n",
    "fnm_mdl = f'{p_out}/model_{param.PRFX}_fld_{param.FLD2USE}_best.p'\n",
    "print('load model', fnm_mdl)\n",
    "mdl.load_state_dict(torch.load(fnm_mdl, map_location=torch.device(DEVICE)))\n",
    "\n",
    "mdl = mdl.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, dl):\n",
    "    lendl=len(dl)\n",
    "    model.eval()\n",
    "    prd = []\n",
    "    for step, dat in enumerate(dl):\n",
    "        if step%1000==0: print(dtnow(), f'step {step}/{lendl}')\n",
    "        xb=dat[0].to(device)\n",
    "        with torch.no_grad(): prdb = model(xb)\n",
    "        prd.append(prdb.cpu().detach().numpy())\n",
    "    prd = np.concatenate(prd)    \n",
    "    return prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdtst = infer(mdl, dltst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub.target = sigmoid(prdtst)\n",
    "print(dfsub.target.mean())\n",
    "dfsub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dfsub.target, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub.to_csv(f'{p_out}/submission_{param.PRFX}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'best_scr {best_scr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mel",
   "language": "python",
   "name": "mel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
