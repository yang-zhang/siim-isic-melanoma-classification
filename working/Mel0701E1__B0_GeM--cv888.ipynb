{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare Mel0701A1__B0SZ224__no_crop_edge--cv8926\n",
    "now GEM https://www.kaggle.com/c/aptos2019-blindness-detection/discussion/108065"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRFX': 'Mel0701E1',\n",
       " 'PRFX_B4': None,\n",
       " 'FLD2USE_B4': 0,\n",
       " 'PRFX_PREP': 'MelPrp0630B1',\n",
       " 'ARCH': 'efficientnet-b0',\n",
       " 'SZ': 224,\n",
       " 'EPOCHS': 100,\n",
       " 'BS': 48,\n",
       " 'K': 5,\n",
       " 'SEED': 101,\n",
       " 'FLD2USE': 0,\n",
       " 'FP16': True,\n",
       " 'PLTFACTOR': 0.5,\n",
       " 'PATIENCE': 5,\n",
       " 'MIN_LR': 1e-08,\n",
       " 'RandomResizedCrop_scale': (0.75, 1.0),\n",
       " 'LR': 0.003,\n",
       " 'WD': 0.001,\n",
       " 'N_SAMPL': None,\n",
       " 'DEBUG': False}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Param: pass\n",
    "param = Param()\n",
    "\n",
    "#########################\n",
    "param.PRFX = 'Mel0701E1'#\n",
    "#########################\n",
    "\n",
    "param.PRFX_B4 = None; param.FLD2USE_B4 = 0\n",
    "param.PRFX_PREP = 'MelPrp0630B1' #MelPrp0630B1__resize_to600\n",
    "param.ARCH = 'efficientnet-b0'\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "param.SZ = EfficientNet.get_image_size(param.ARCH) \n",
    "\n",
    "param.EPOCHS = 100\n",
    "\n",
    "# p2: efficientnet-b1 64\n",
    "param.BS = 48\n",
    "\n",
    "param.K=5; param.SEED=101; param.FLD2USE=0\n",
    "param.FP16 = True\n",
    "param.PLTFACTOR=0.5; param.PATIENCE=5; param.MIN_LR=1e-8\n",
    "\n",
    "param.RandomResizedCrop_scale=(0.75, 1.0)\n",
    "\n",
    "param.LR=3e-3\n",
    "param.WD=1e-3\n",
    "\n",
    "param.N_SAMPL = None\n",
    "\n",
    "param.DEBUG = False\n",
    "if param.DEBUG: \n",
    "    param.EPOCHS = 5\n",
    "    param.K = 5\n",
    "    param.N_SAMPL = 256\n",
    "\n",
    "DEVICE = 'cuda'; PIN_MEM = (DEVICE=='cuda'); N_WORKERS=4\n",
    "\n",
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  2 04:24:45 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   64C    P0    76W / 300W |  12073MiB / 16160MiB |     99%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     10867      C   /data/anaconda3/envs/mel/bin/python         7227MiB |\r\n",
      "|    0     27057      C   /data/anaconda3/envs/mel/bin/python         4831MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os, sys, gc\n",
    "import datetime\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score as roc_auc\n",
    "\n",
    "# https://github.com/eriklindernoren/PyTorch-YOLOv3/issues/162#issuecomment-491115265\n",
    "from PIL import ImageFile; ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "import torch\n",
    "device=torch.device(DEVICE)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "set_seed(param.SEED)\n",
    "\n",
    "\n",
    "\n",
    "p_out = f'../output/{param.PRFX}'; Path(p_out).mkdir(exist_ok=True,parents=True)\n",
    "p_cmp = '../input/siim-isic-melanoma-classification'\n",
    "p_b4  = f'../output/{param.PRFX_B4}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58457, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>im_pth</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24437</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0630B1/siim-isic-melanoma-clas...</td>\n",
       "      <td>IP_4021847</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57432</th>\n",
       "      <td>19</td>\n",
       "      <td>../output/MelPrp0630B1/andrewmvd--isic-2019/IS...</td>\n",
       "      <td>BCN_0004730</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                             im_pth   patient_id  \\\n",
       "24437      20  ../output/MelPrp0630B1/siim-isic-melanoma-clas...   IP_4021847   \n",
       "57432      19  ../output/MelPrp0630B1/andrewmvd--isic-2019/IS...  BCN_0004730   \n",
       "\n",
       "       target  \n",
       "24437     0.0  \n",
       "57432     1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(58457, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    33126\n",
       "19    25331\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "19    0.178516\n",
       "20    0.017630\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_prp = f'../output/{param.PRFX_PREP}'\n",
    "dftrn = pd.read_csv(f'{p_prp}/train_all.csv') \n",
    "print(dftrn.shape)\n",
    "\n",
    "set_seed(param.SEED); dftrn = dftrn.sample(frac=1.)\n",
    "\n",
    "if param.N_SAMPL is not None: dftrn = dftrn.head(param.N_SAMPL)\n",
    "    \n",
    "display(dftrn.head(2))\n",
    "display(dftrn.shape)\n",
    "display(dftrn.source.value_counts())\n",
    "display(dftrn.groupby('source').target.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/mel/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "idx_nopid=np.where(dftrn.patient_id.isna())[0]\n",
    "print(len(idx_nopid))\n",
    "dftrn['patient_id'].iloc[idx_nopid]=[f'Nan_{i}' for i in range(len(idx_nopid))]\n",
    "assert dftrn.patient_id.isna().mean()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 46765 11692\n",
      "1 46765 11692\n",
      "2 46766 11691\n",
      "3 46766 11691\n",
      "4 46766 11691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.913953\n",
       "1.0    0.086047\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.911066\n",
       "1.0    0.088934\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.915173\n",
       "1.0    0.084827\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.91218\n",
       "1.0    0.08782\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.910897\n",
       "1.0    0.089103\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26536\n",
       "19    20229\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26644\n",
       "19    20121\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26529\n",
       "19    20237\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26491\n",
       "19    20275\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26304\n",
       "19    20462\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(param.SEED)\n",
    "kf = GroupKFold(n_splits=param.K)\n",
    "fld2trvl={fld:(tr,vl) for fld,(tr,vl) in enumerate(kf.split(dftrn, groups=dftrn.patient_id))}\n",
    "\n",
    "for fld, (tr, vl) in fld2trvl.items():\n",
    "    print(fld, len(tr), len(vl))\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    dfvl=dftrn.iloc[vl]\n",
    "    assert set(dftr.patient_id)&set(dfvl.patient_id)==set()\n",
    "for fld, (tr, vl) in fld2trvl.items():\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    display(dftr.target.value_counts()/len(tr))\n",
    "for fld, (tr, vl) in fld2trvl.items():\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    display(dftr.source.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(Dataset):\n",
    "    def __init__(self, df, mode='trn'):\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        if mode=='trn':\n",
    "            self.composed = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(param.SZ, scale=param.RandomResizedCrop_scale),\n",
    "#                 transforms.RandomHorizontalFlip(),\n",
    "#                 transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(180),\n",
    "                transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ])    \n",
    "        else:\n",
    "            self.composed = transforms.Compose([\n",
    "                transforms.Resize((param.SZ, param.SZ)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ])    \n",
    "    def __getitem__(self, i):\n",
    "        x = Image.open(self.df.im_pth.values[i]) \n",
    "        x = self.composed(x)\n",
    "        if self.mode in ('trn', 'val'):\n",
    "            y = self.df.target.values[i]\n",
    "            return x, y\n",
    "        else:\n",
    "            return (x,)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)       \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkmdl():  \n",
    "    mdl = EfficientNet.from_pretrained(param.ARCH, num_classes=1)\n",
    "    mdl._avg_pooling = GeM()\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "mdl = mkmdl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): GeM(p=3.0000, eps=1e-06)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    prd = []\n",
    "    y = []\n",
    "    for step, dat in enumerate(dl):\n",
    "        xb, yb = (o.to(device) for o in dat)\n",
    "        with torch.no_grad(): prdb = model(xb)\n",
    "        prd.append(prdb.cpu().detach().numpy())\n",
    "        y.append(yb.cpu().detach().numpy())\n",
    "    prd = np.concatenate(prd)    \n",
    "    y = np.concatenate(y)    \n",
    "    lss = F.binary_cross_entropy_with_logits(torch.tensor(prd),torch.tensor(y).unsqueeze(1)).item()\n",
    "    scr = roc_auc(y, prd)\n",
    "    return lss, scr, y, prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "mdl = mkmdl()\n",
    "mdl = mdl.to(device)\n",
    "\n",
    "if param.PRFX_B4 is not None: \n",
    "    fnm_mdl_b4 = f'{p_b4}/model_{param.PRFX_B4}_fld_{param.FLD2USE_B4}_best.p'\n",
    "    print('load previously trained', fnm_mdl_b4)\n",
    "    mdl.load_state_dict(torch.load(fnm_mdl_b4, map_location=torch.device(DEVICE)))\n",
    "\n",
    "\n",
    "# opt = optim.SGD(mdl.parameters(), lr=param.LR, momentum=param.MOMENTUM, weight_decay=param.WD)\n",
    "opt = optim.Adam(mdl.parameters(), lr=param.LR, weight_decay=param.WD)\n",
    "schdl = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=param.PLTFACTOR, patience=param.PATIENCE, min_lr=param.MIN_LR, verbose=True)\n",
    "if param.FP16: mdl, opt = amp.initialize(mdl, opt, opt_level='O1', verbosity=0)\n",
    "mdl.zero_grad()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46765 11692\n",
      "46765 11692\n",
      "975 122\n"
     ]
    }
   ],
   "source": [
    "tr,vl=fld2trvl[param.FLD2USE]\n",
    "dftr=dftrn.iloc[tr]\n",
    "dfvl=dftrn.iloc[vl]\n",
    "ystr=dftr.target.values\n",
    "ysvl=dfvl.target.values\n",
    "print(len(dftr), len(dfvl))\n",
    "dstr = MelDataset(dftr, mode='trn')\n",
    "dsvl = MelDataset(dfvl, mode='val')\n",
    "print(len(dstr), len(dsvl))\n",
    "dltr = DataLoader(dstr, batch_size=param.BS,   shuffle=True,  num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "dlvl = DataLoader(dsvl, batch_size=param.BS*2, shuffle=False, num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "print(len(dltr), len(dlvl))\n",
    "lendl=len(dltr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['fld2trvl'] = fld2trvl\n",
    "results['param'] = param\n",
    "\n",
    "stats = {\n",
    "    'lss': {'tr':[],'vl':[]},\n",
    "    'scr': {'tr':[],'vl':[]},\n",
    "}\n",
    "oof = {'y':[], 'prd':[]}\n",
    "\n",
    "\n",
    "def save_results():\n",
    "    results['oof'] = oof\n",
    "    stats['best_scr'] = best_scr\n",
    "    stats['best_epc'] = best_epc\n",
    "    results['stats'] = stats\n",
    "    pickle.dump(results, open(f'{p_out}/results_{param.PRFX}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-02 04:33:51 ep 0: lss_tr 0.247; lss_vl 0.310; scr_tr 0.801; scr_vl 0.844; \n",
      "better scr -inf -> 0.844\n",
      "2020-07-02 04:42:45 ep 1: lss_tr 0.228; lss_vl 0.340; scr_tr 0.838; scr_vl 0.836; \n",
      "2020-07-02 04:51:40 ep 2: lss_tr 0.229; lss_vl 0.319; scr_tr 0.835; scr_vl 0.859; \n",
      "better scr 0.844 -> 0.859\n",
      "2020-07-02 05:00:29 ep 3: lss_tr 0.230; lss_vl 0.322; scr_tr 0.834; scr_vl 0.860; \n",
      "better scr 0.859 -> 0.860\n",
      "2020-07-02 05:09:30 ep 4: lss_tr 0.229; lss_vl 0.274; scr_tr 0.836; scr_vl 0.865; \n",
      "better scr 0.860 -> 0.865\n",
      "2020-07-02 05:18:38 ep 5: lss_tr 0.230; lss_vl 0.295; scr_tr 0.833; scr_vl 0.848; \n",
      "2020-07-02 05:28:04 ep 6: lss_tr 0.228; lss_vl 0.223; scr_tr 0.838; scr_vl 0.873; \n",
      "better scr 0.865 -> 0.873\n",
      "2020-07-02 05:37:11 ep 7: lss_tr 0.227; lss_vl 0.225; scr_tr 0.840; scr_vl 0.867; \n",
      "2020-07-02 05:46:32 ep 8: lss_tr 0.227; lss_vl 0.280; scr_tr 0.840; scr_vl 0.867; \n",
      "2020-07-02 05:56:02 ep 9: lss_tr 0.229; lss_vl 0.225; scr_tr 0.836; scr_vl 0.868; \n",
      "2020-07-02 06:05:20 ep 10: lss_tr 0.228; lss_vl 0.247; scr_tr 0.837; scr_vl 0.879; \n",
      "better scr 0.873 -> 0.879\n",
      "2020-07-02 06:14:41 ep 11: lss_tr 0.227; lss_vl 0.252; scr_tr 0.839; scr_vl 0.879; \n",
      "2020-07-02 06:23:34 ep 12: lss_tr 0.227; lss_vl 0.261; scr_tr 0.839; scr_vl 0.860; \n",
      "2020-07-02 06:32:47 ep 13: lss_tr 0.227; lss_vl 0.234; scr_tr 0.840; scr_vl 0.871; \n",
      "2020-07-02 06:41:50 ep 14: lss_tr 0.227; lss_vl 0.257; scr_tr 0.839; scr_vl 0.872; \n",
      "2020-07-02 06:50:47 ep 15: lss_tr 0.227; lss_vl 0.355; scr_tr 0.840; scr_vl 0.877; \n",
      "2020-07-02 06:59:45 ep 16: lss_tr 0.227; lss_vl 0.266; scr_tr 0.839; scr_vl 0.867; \n",
      "Epoch    17: reducing learning rate of group 0 to 1.5000e-03.\n",
      "2020-07-02 07:08:41 ep 17: lss_tr 0.224; lss_vl 0.303; scr_tr 0.847; scr_vl 0.866; \n",
      "2020-07-02 07:17:36 ep 18: lss_tr 0.222; lss_vl 0.228; scr_tr 0.849; scr_vl 0.878; \n",
      "2020-07-02 07:26:28 ep 19: lss_tr 0.223; lss_vl 0.219; scr_tr 0.848; scr_vl 0.882; \n",
      "better scr 0.879 -> 0.882\n",
      "2020-07-02 07:35:21 ep 20: lss_tr 0.223; lss_vl 0.231; scr_tr 0.849; scr_vl 0.880; \n",
      "2020-07-02 07:44:34 ep 21: lss_tr 0.222; lss_vl 0.296; scr_tr 0.850; scr_vl 0.866; \n",
      "2020-07-02 07:53:52 ep 22: lss_tr 0.222; lss_vl 0.224; scr_tr 0.850; scr_vl 0.871; \n",
      "2020-07-02 08:02:53 ep 23: lss_tr 0.223; lss_vl 0.222; scr_tr 0.848; scr_vl 0.874; \n",
      "2020-07-02 08:11:52 ep 24: lss_tr 0.223; lss_vl 0.260; scr_tr 0.848; scr_vl 0.874; \n",
      "2020-07-02 08:20:36 ep 25: lss_tr 0.222; lss_vl 0.216; scr_tr 0.851; scr_vl 0.884; \n",
      "better scr 0.882 -> 0.884\n",
      "2020-07-02 08:29:35 ep 26: lss_tr 0.222; lss_vl 0.226; scr_tr 0.850; scr_vl 0.882; \n",
      "2020-07-02 08:38:37 ep 27: lss_tr 0.222; lss_vl 0.231; scr_tr 0.849; scr_vl 0.881; \n",
      "2020-07-02 08:47:38 ep 28: lss_tr 0.221; lss_vl 0.246; scr_tr 0.851; scr_vl 0.873; \n",
      "2020-07-02 08:56:28 ep 29: lss_tr 0.222; lss_vl 0.243; scr_tr 0.849; scr_vl 0.878; \n",
      "2020-07-02 09:05:25 ep 30: lss_tr 0.222; lss_vl 0.225; scr_tr 0.849; scr_vl 0.884; \n",
      "2020-07-02 09:14:19 ep 31: lss_tr 0.221; lss_vl 0.218; scr_tr 0.852; scr_vl 0.881; \n",
      "Epoch    32: reducing learning rate of group 0 to 7.5000e-04.\n",
      "2020-07-02 09:23:13 ep 32: lss_tr 0.220; lss_vl 0.215; scr_tr 0.854; scr_vl 0.884; \n",
      "better scr 0.884 -> 0.884\n",
      "2020-07-02 09:32:14 ep 33: lss_tr 0.220; lss_vl 0.216; scr_tr 0.854; scr_vl 0.883; \n",
      "2020-07-02 09:41:14 ep 34: lss_tr 0.219; lss_vl 0.244; scr_tr 0.855; scr_vl 0.886; \n",
      "better scr 0.884 -> 0.886\n",
      "2020-07-02 09:50:13 ep 35: lss_tr 0.219; lss_vl 0.213; scr_tr 0.855; scr_vl 0.888; \n",
      "better scr 0.886 -> 0.888\n",
      "2020-07-02 09:59:28 ep 36: lss_tr 0.220; lss_vl 0.218; scr_tr 0.854; scr_vl 0.881; \n",
      "2020-07-02 10:08:57 ep 37: lss_tr 0.220; lss_vl 0.213; scr_tr 0.854; scr_vl 0.884; \n",
      "2020-07-02 10:18:21 ep 38: lss_tr 0.219; lss_vl 0.221; scr_tr 0.855; scr_vl 0.882; \n",
      "2020-07-02 10:27:32 ep 39: lss_tr 0.219; lss_vl 0.219; scr_tr 0.855; scr_vl 0.884; \n",
      "2020-07-02 10:36:29 ep 40: lss_tr 0.218; lss_vl 0.214; scr_tr 0.856; scr_vl 0.886; \n",
      "2020-07-02 10:45:23 ep 41: lss_tr 0.220; lss_vl 0.220; scr_tr 0.854; scr_vl 0.884; \n",
      "Epoch    42: reducing learning rate of group 0 to 3.7500e-04.\n",
      "2020-07-02 10:54:16 ep 42: lss_tr 0.217; lss_vl 0.211; scr_tr 0.860; scr_vl 0.887; \n",
      "2020-07-02 11:03:15 ep 43: lss_tr 0.217; lss_vl 0.237; scr_tr 0.859; scr_vl 0.881; \n",
      "2020-07-02 11:12:07 ep 44: lss_tr 0.217; lss_vl 0.213; scr_tr 0.859; scr_vl 0.885; \n",
      "2020-07-02 11:21:07 ep 45: lss_tr 0.217; lss_vl 0.213; scr_tr 0.859; scr_vl 0.885; \n",
      "2020-07-02 11:29:44 ep 46: lss_tr 0.216; lss_vl 0.211; scr_tr 0.860; scr_vl 0.887; \n",
      "2020-07-02 11:37:19 ep 47: lss_tr 0.216; lss_vl 0.218; scr_tr 0.861; scr_vl 0.885; \n",
      "Epoch    48: reducing learning rate of group 0 to 1.8750e-04.\n",
      "2020-07-02 11:46:13 ep 48: lss_tr 0.216; lss_vl 0.213; scr_tr 0.860; scr_vl 0.886; \n",
      "2020-07-02 11:55:29 ep 49: lss_tr 0.217; lss_vl 0.212; scr_tr 0.859; scr_vl 0.887; \n",
      "2020-07-02 12:04:24 ep 50: lss_tr 0.216; lss_vl 0.215; scr_tr 0.862; scr_vl 0.886; \n",
      "2020-07-02 12:13:30 ep 51: lss_tr 0.216; lss_vl 0.216; scr_tr 0.860; scr_vl 0.888; \n",
      "better scr 0.888 -> 0.888\n",
      "2020-07-02 12:22:32 ep 52: lss_tr 0.216; lss_vl 0.210; scr_tr 0.862; scr_vl 0.888; \n",
      "better scr 0.888 -> 0.888\n",
      "2020-07-02 12:31:41 ep 53: lss_tr 0.216; lss_vl 0.215; scr_tr 0.861; scr_vl 0.887; \n",
      "2020-07-02 12:40:44 ep 54: lss_tr 0.217; lss_vl 0.213; scr_tr 0.859; scr_vl 0.888; \n",
      "better scr 0.888 -> 0.888\n",
      "2020-07-02 12:50:33 ep 55: lss_tr 0.216; lss_vl 0.211; scr_tr 0.862; scr_vl 0.888; \n",
      "2020-07-02 12:59:36 ep 56: lss_tr 0.216; lss_vl 0.214; scr_tr 0.861; scr_vl 0.888; \n",
      "2020-07-02 13:08:41 ep 57: lss_tr 0.217; lss_vl 0.211; scr_tr 0.859; scr_vl 0.888; \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6b2e6594f842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFP16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/mel/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/mel/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_scr = float('-inf')\n",
    "best_epc = -1\n",
    "for epc in range(param.EPOCHS):\n",
    "    prdtr_ep=[]\n",
    "    ytr_ep=[]\n",
    "    for step, dat in enumerate(dltr):\n",
    "        mdl.train()\n",
    "        xb,yb=(o.to(device) for o in dat)\n",
    "        yb = yb.unsqueeze(1)\n",
    "        prdb = mdl(xb)\n",
    "        loss = F.binary_cross_entropy_with_logits(prdb, yb)\n",
    "        if param.FP16:\n",
    "            with amp.scale_loss(loss, opt) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        if param.FP16:\n",
    "            torch.nn.utils.clip_grad_norm_(amp.master_params(opt), 1)\n",
    "        else:\n",
    "            torch.nn.utils.clip_grad_norm_(mdl.parameters(), 1)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        prdtr_ep.append(prdb.cpu().detach().numpy())\n",
    "        ytr_ep.append(yb.cpu().detach().numpy())\n",
    "        if step>0 and step%1000==0: print(dtnow(), f'ep {epc} step {step}/{lendl}')\n",
    "    \n",
    "    prdtr_ep = np.concatenate(prdtr_ep)\n",
    "    ytr_ep = np.concatenate(ytr_ep)    \n",
    "    lss_tr_ep = F.binary_cross_entropy_with_logits(torch.tensor(prdtr_ep),torch.tensor(ytr_ep)).item()\n",
    "    scr_tr_ep = roc_auc(ytr_ep, prdtr_ep)\n",
    "    stats['lss']['tr'].append(lss_tr_ep)\n",
    "    stats['scr']['tr'].append(scr_tr_ep)\n",
    "    \n",
    "    lss_vl_ep, scr_vl_ep, yvl_ep, prdvl_ep = evaluate(mdl, dlvl)\n",
    "    stats['lss']['vl'].append(lss_vl_ep)\n",
    "    stats['scr']['vl'].append(scr_vl_ep)\n",
    "    oof['y'].append(yvl_ep)\n",
    "    oof['prd'].append(prdvl_ep)\n",
    "    \n",
    "    print(dtnow(), f'ep {epc}: lss_tr {lss_tr_ep:.3f}; lss_vl {lss_vl_ep:.3f}; scr_tr {scr_tr_ep:.3f}; scr_vl {scr_vl_ep:.3f}; ')\n",
    "    \n",
    "    if scr_vl_ep>best_scr:\n",
    "        print(f'better scr {best_scr:.3f} -> {scr_vl_ep:.3f}')\n",
    "        best_scr = scr_vl_ep\n",
    "        best_epc = epc\n",
    "        torch.save(mdl.state_dict(), f'{p_out}/model_{param.PRFX}_fld_{param.FLD2USE}_best.p')\n",
    "    if not param.DEBUG: torch.save(mdl.state_dict(), f'{p_out}/model_{param.PRFX}_fld_{param.FLD2USE}_epc_{epc}.p')\n",
    "        \n",
    "    schdl.step(scr_vl_ep)  # Update learning rate schedule\n",
    "    save_results()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_scr 0.8884; best_epc 54\n"
     ]
    }
   ],
   "source": [
    "print(f'best_scr {best_scr:.4f}; best_epc {best_epc}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pd.DataFrame(stats['lss'])\n",
    "\n",
    "pd.DataFrame(stats['scr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for mtrc in ['lss', 'scr']:\n",
    "    recs=stats[mtrc]\n",
    "    for tv,vs in recs.items():\n",
    "        plt.title(f'{mtrc}')\n",
    "        plt.plot(vs, 'o--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>im_pth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>IP_3579794</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../output/MelPrp0630B1/siim-isic-melanoma-clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>IP_7782715</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>../output/MelPrp0630B1/siim-isic-melanoma-clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>IP_7960270</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>../output/MelPrp0630B1/siim-isic-melanoma-clas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_0052060  IP_3579794    male        70.0                           NaN   \n",
       "1  ISIC_0052349  IP_7782715    male        40.0               lower extremity   \n",
       "2  ISIC_0058510  IP_7960270  female        55.0                         torso   \n",
       "\n",
       "                                              im_pth  \n",
       "0  ../output/MelPrp0630B1/siim-isic-melanoma-clas...  \n",
       "1  ../output/MelPrp0630B1/siim-isic-melanoma-clas...  \n",
       "2  ../output/MelPrp0630B1/siim-isic-melanoma-clas...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10982\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "dftst = pd.read_csv(f'{p_prp}/test.csv', nrows=128 if param.DEBUG else None) \n",
    "display(dftst.head(3))\n",
    "\n",
    "dfsub = pd.read_csv(f'{p_cmp}/sample_submission.csv', nrows=128 if param.DEBUG else None) \n",
    "\n",
    "dstst = MelDataset(dftst, mode='tst')\n",
    "print(len(dstst))\n",
    "dltst = DataLoader(dstst, batch_size=param.BS*2, shuffle=False, num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "print(len(dltst))\n",
    "lendl=len(dltst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "load model ../output/Mel0701E1/model_Mel0701E1_fld_0_best.p\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"_blocks.1._expand_conv.weight\", \"_blocks.1._bn0.weight\", \"_blocks.1._bn0.bias\", \"_blocks.1._bn0.running_mean\", \"_blocks.1._bn0.running_var\", \"_avg_pooling.p\". \n\tUnexpected key(s) in state_dict: \"_blocks.16._expand_conv.weight\", \"_blocks.16._bn0.weight\", \"_blocks.16._bn0.bias\", \"_blocks.16._bn0.running_mean\", \"_blocks.16._bn0.running_var\", \"_blocks.16._bn0.num_batches_tracked\", \"_blocks.16._depthwise_conv.weight\", \"_blocks.16._bn1.weight\", \"_blocks.16._bn1.bias\", \"_blocks.16._bn1.running_mean\", \"_blocks.16._bn1.running_var\", \"_blocks.16._bn1.num_batches_tracked\", \"_blocks.16._se_reduce.weight\", \"_blocks.16._se_reduce.bias\", \"_blocks.16._se_expand.weight\", \"_blocks.16._se_expand.bias\", \"_blocks.16._project_conv.weight\", \"_blocks.16._bn2.weight\", \"_blocks.16._bn2.bias\", \"_blocks.16._bn2.running_mean\", \"_blocks.16._bn2.running_var\", \"_blocks.16._bn2.num_batches_tracked\", \"_blocks.17._expand_conv.weight\", \"_blocks.17._bn0.weight\", \"_blocks.17._bn0.bias\", \"_blocks.17._bn0.running_mean\", \"_blocks.17._bn0.running_var\", \"_blocks.17._bn0.num_batches_tracked\", \"_blocks.17._depthwise_conv.weight\", \"_blocks.17._bn1.weight\", \"_blocks.17._bn1.bias\", \"_blocks.17._bn1.running_mean\", \"_blocks.17._bn1.running_var\", \"_blocks.17._bn1.num_batches_tracked\", \"_blocks.17._se_reduce.weight\", \"_blocks.17._se_reduce.bias\", \"_blocks.17._se_expand.weight\", \"_blocks.17._se_expand.bias\", \"_blocks.17._project_conv.weight\", \"_blocks.17._bn2.weight\", \"_blocks.17._bn2.bias\", \"_blocks.17._bn2.running_mean\", \"_blocks.17._bn2.running_var\", \"_blocks.17._bn2.num_batches_tracked\", \"_blocks.18._expand_conv.weight\", \"_blocks.18._bn0.weight\", \"_blocks.18._bn0.bias\", \"_blocks.18._bn0.running_mean\", \"_blocks.18._bn0.running_var\", \"_blocks.18._bn0.num_batches_tracked\", \"_blocks.18._depthwise_conv.weight\", \"_blocks.18._bn1.weight\", \"_blocks.18._bn1.bias\", \"_blocks.18._bn1.running_mean\", \"_blocks.18._bn1.running_var\", \"_blocks.18._bn1.num_batches_tracked\", \"_blocks.18._se_reduce.weight\", \"_blocks.18._se_reduce.bias\", \"_blocks.18._se_expand.weight\", \"_blocks.18._se_expand.bias\", \"_blocks.18._project_conv.weight\", \"_blocks.18._bn2.weight\", \"_blocks.18._bn2.bias\", \"_blocks.18._bn2.running_mean\", \"_blocks.18._bn2.running_var\", \"_blocks.18._bn2.num_batches_tracked\", \"_blocks.19._expand_conv.weight\", \"_blocks.19._bn0.weight\", \"_blocks.19._bn0.bias\", \"_blocks.19._bn0.running_mean\", \"_blocks.19._bn0.running_var\", \"_blocks.19._bn0.num_batches_tracked\", \"_blocks.19._depthwise_conv.weight\", \"_blocks.19._bn1.weight\", \"_blocks.19._bn1.bias\", \"_blocks.19._bn1.running_mean\", \"_blocks.19._bn1.running_var\", \"_blocks.19._bn1.num_batches_tracked\", \"_blocks.19._se_reduce.weight\", \"_blocks.19._se_reduce.bias\", \"_blocks.19._se_expand.weight\", \"_blocks.19._se_expand.bias\", \"_blocks.19._project_conv.weight\", \"_blocks.19._bn2.weight\", \"_blocks.19._bn2.bias\", \"_blocks.19._bn2.running_mean\", \"_blocks.19._bn2.running_var\", \"_blocks.19._bn2.num_batches_tracked\", \"_blocks.20._expand_conv.weight\", \"_blocks.20._bn0.weight\", \"_blocks.20._bn0.bias\", \"_blocks.20._bn0.running_mean\", \"_blocks.20._bn0.running_var\", \"_blocks.20._bn0.num_batches_tracked\", \"_blocks.20._depthwise_conv.weight\", \"_blocks.20._bn1.weight\", \"_blocks.20._bn1.bias\", \"_blocks.20._bn1.running_mean\", \"_blocks.20._bn1.running_var\", \"_blocks.20._bn1.num_batches_tracked\", \"_blocks.20._se_reduce.weight\", \"_blocks.20._se_reduce.bias\", \"_blocks.20._se_expand.weight\", \"_blocks.20._se_expand.bias\", \"_blocks.20._project_conv.weight\", \"_blocks.20._bn2.weight\", \"_blocks.20._bn2.bias\", \"_blocks.20._bn2.running_mean\", \"_blocks.20._bn2.running_var\", \"_blocks.20._bn2.num_batches_tracked\", \"_blocks.21._expand_conv.weight\", \"_blocks.21._bn0.weight\", \"_blocks.21._bn0.bias\", \"_blocks.21._bn0.running_mean\", \"_blocks.21._bn0.running_var\", \"_blocks.21._bn0.num_batches_tracked\", \"_blocks.21._depthwise_conv.weight\", \"_blocks.21._bn1.weight\", \"_blocks.21._bn1.bias\", \"_blocks.21._bn1.running_mean\", \"_blocks.21._bn1.running_var\", \"_blocks.21._bn1.num_batches_tracked\", \"_blocks.21._se_reduce.weight\", \"_blocks.21._se_reduce.bias\", \"_blocks.21._se_expand.weight\", \"_blocks.21._se_expand.bias\", \"_blocks.21._project_conv.weight\", \"_blocks.21._bn2.weight\", \"_blocks.21._bn2.bias\", \"_blocks.21._bn2.running_mean\", \"_blocks.21._bn2.running_var\", \"_blocks.21._bn2.num_batches_tracked\", \"_blocks.22._expand_conv.weight\", \"_blocks.22._bn0.weight\", \"_blocks.22._bn0.bias\", \"_blocks.22._bn0.running_mean\", \"_blocks.22._bn0.running_var\", \"_blocks.22._bn0.num_batches_tracked\", \"_blocks.22._depthwise_conv.weight\", \"_blocks.22._bn1.weight\", \"_blocks.22._bn1.bias\", \"_blocks.22._bn1.running_mean\", \"_blocks.22._bn1.running_var\", \"_blocks.22._bn1.num_batches_tracked\", \"_blocks.22._se_reduce.weight\", \"_blocks.22._se_reduce.bias\", \"_blocks.22._se_expand.weight\", \"_blocks.22._se_expand.bias\", \"_blocks.22._project_conv.weight\", \"_blocks.22._bn2.weight\", \"_blocks.22._bn2.bias\", \"_blocks.22._bn2.running_mean\", \"_blocks.22._bn2.running_var\", \"_blocks.22._bn2.num_batches_tracked\". \n\tsize mismatch for _blocks.1._depthwise_conv.weight: copying a param with shape torch.Size([16, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 1, 3, 3]).\n\tsize mismatch for _blocks.1._bn1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for _blocks.1._bn1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for _blocks.1._bn1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for _blocks.1._bn1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for _blocks.1._se_reduce.weight: copying a param with shape torch.Size([4, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 96, 1, 1]).\n\tsize mismatch for _blocks.1._se_expand.weight: copying a param with shape torch.Size([16, 4, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 4, 1, 1]).\n\tsize mismatch for _blocks.1._se_expand.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for _blocks.1._project_conv.weight: copying a param with shape torch.Size([16, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([24, 96, 1, 1]).\n\tsize mismatch for _blocks.1._bn2.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for _blocks.1._bn2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for _blocks.1._bn2.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for _blocks.1._bn2.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for _blocks.2._expand_conv.weight: copying a param with shape torch.Size([96, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([144, 24, 1, 1]).\n\tsize mismatch for _blocks.2._bn0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn0.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn0.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._depthwise_conv.weight: copying a param with shape torch.Size([96, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([144, 1, 3, 3]).\n\tsize mismatch for _blocks.2._bn1.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn1.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn1.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._se_reduce.weight: copying a param with shape torch.Size([4, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([6, 144, 1, 1]).\n\tsize mismatch for _blocks.2._se_reduce.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([6]).\n\tsize mismatch for _blocks.2._se_expand.weight: copying a param with shape torch.Size([96, 4, 1, 1]) from checkpoint, the shape in current model is torch.Size([144, 6, 1, 1]).\n\tsize mismatch for _blocks.2._se_expand.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._project_conv.weight: copying a param with shape torch.Size([24, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([24, 144, 1, 1]).\n\tsize mismatch for _blocks.3._depthwise_conv.weight: copying a param with shape torch.Size([144, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([144, 1, 5, 5]).\n\tsize mismatch for _blocks.3._project_conv.weight: copying a param with shape torch.Size([24, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 144, 1, 1]).\n\tsize mismatch for _blocks.3._bn2.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.3._bn2.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.3._bn2.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.3._bn2.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.4._expand_conv.weight: copying a param with shape torch.Size([144, 24, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 40, 1, 1]).\n\tsize mismatch for _blocks.4._bn0.weight: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn0.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn0.running_mean: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn0.running_var: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._depthwise_conv.weight: copying a param with shape torch.Size([144, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 1, 5, 5]).\n\tsize mismatch for _blocks.4._bn1.weight: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn1.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn1.running_mean: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn1.running_var: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._se_reduce.weight: copying a param with shape torch.Size([6, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 240, 1, 1]).\n\tsize mismatch for _blocks.4._se_reduce.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([10]).\n\tsize mismatch for _blocks.4._se_expand.weight: copying a param with shape torch.Size([144, 6, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 10, 1, 1]).\n\tsize mismatch for _blocks.4._se_expand.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._project_conv.weight: copying a param with shape torch.Size([24, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 240, 1, 1]).\n\tsize mismatch for _blocks.4._bn2.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.4._bn2.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.4._bn2.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.4._bn2.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.5._expand_conv.weight: copying a param with shape torch.Size([144, 24, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 40, 1, 1]).\n\tsize mismatch for _blocks.5._bn0.weight: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn0.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn0.running_mean: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn0.running_var: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._depthwise_conv.weight: copying a param with shape torch.Size([144, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([240, 1, 3, 3]).\n\tsize mismatch for _blocks.5._bn1.weight: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn1.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn1.running_mean: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn1.running_var: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._se_reduce.weight: copying a param with shape torch.Size([6, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 240, 1, 1]).\n\tsize mismatch for _blocks.5._se_reduce.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([10]).\n\tsize mismatch for _blocks.5._se_expand.weight: copying a param with shape torch.Size([144, 6, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 10, 1, 1]).\n\tsize mismatch for _blocks.5._se_expand.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._project_conv.weight: copying a param with shape torch.Size([40, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 240, 1, 1]).\n\tsize mismatch for _blocks.5._bn2.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.5._bn2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.5._bn2.running_mean: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.5._bn2.running_var: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.6._expand_conv.weight: copying a param with shape torch.Size([240, 40, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for _blocks.6._bn0.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn0.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn0.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn0.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._depthwise_conv.weight: copying a param with shape torch.Size([240, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([480, 1, 3, 3]).\n\tsize mismatch for _blocks.6._bn1.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn1.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn1.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn1.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._se_reduce.weight: copying a param with shape torch.Size([10, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for _blocks.6._se_reduce.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for _blocks.6._se_expand.weight: copying a param with shape torch.Size([240, 10, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for _blocks.6._se_expand.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._project_conv.weight: copying a param with shape torch.Size([40, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 480, 1, 1]).\n\tsize mismatch for _blocks.6._bn2.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.6._bn2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.6._bn2.running_mean: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.6._bn2.running_var: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.7._expand_conv.weight: copying a param with shape torch.Size([240, 40, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for _blocks.7._bn0.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn0.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn0.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn0.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._depthwise_conv.weight: copying a param with shape torch.Size([240, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([480, 1, 3, 3]).\n\tsize mismatch for _blocks.7._bn1.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn1.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn1.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn1.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._se_reduce.weight: copying a param with shape torch.Size([10, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for _blocks.7._se_reduce.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for _blocks.7._se_expand.weight: copying a param with shape torch.Size([240, 10, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for _blocks.7._se_expand.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._project_conv.weight: copying a param with shape torch.Size([40, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 480, 1, 1]).\n\tsize mismatch for _blocks.7._bn2.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.7._bn2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.7._bn2.running_mean: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.7._bn2.running_var: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.8._expand_conv.weight: copying a param with shape torch.Size([240, 40, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for _blocks.8._bn0.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn0.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn0.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn0.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._depthwise_conv.weight: copying a param with shape torch.Size([240, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([480, 1, 5, 5]).\n\tsize mismatch for _blocks.8._bn1.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn1.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn1.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn1.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._se_reduce.weight: copying a param with shape torch.Size([10, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for _blocks.8._se_reduce.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for _blocks.8._se_expand.weight: copying a param with shape torch.Size([240, 10, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for _blocks.8._se_expand.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._project_conv.weight: copying a param with shape torch.Size([80, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 480, 1, 1]).\n\tsize mismatch for _blocks.8._bn2.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.8._bn2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.8._bn2.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.8._bn2.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.9._expand_conv.weight: copying a param with shape torch.Size([480, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for _blocks.9._bn0.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn0.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn0.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn0.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._depthwise_conv.weight: copying a param with shape torch.Size([480, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for _blocks.9._bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._se_reduce.weight: copying a param with shape torch.Size([20, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for _blocks.9._se_reduce.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for _blocks.9._se_expand.weight: copying a param with shape torch.Size([480, 20, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for _blocks.9._se_expand.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._project_conv.weight: copying a param with shape torch.Size([80, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 672, 1, 1]).\n\tsize mismatch for _blocks.9._bn2.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.9._bn2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.9._bn2.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.9._bn2.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.10._expand_conv.weight: copying a param with shape torch.Size([480, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for _blocks.10._bn0.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn0.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn0.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn0.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._depthwise_conv.weight: copying a param with shape torch.Size([480, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for _blocks.10._bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._se_reduce.weight: copying a param with shape torch.Size([20, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for _blocks.10._se_reduce.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for _blocks.10._se_expand.weight: copying a param with shape torch.Size([480, 20, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for _blocks.10._se_expand.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._project_conv.weight: copying a param with shape torch.Size([80, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 672, 1, 1]).\n\tsize mismatch for _blocks.10._bn2.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.10._bn2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.10._bn2.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.10._bn2.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.11._expand_conv.weight: copying a param with shape torch.Size([480, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for _blocks.11._bn0.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn0.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn0.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn0.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._depthwise_conv.weight: copying a param with shape torch.Size([480, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for _blocks.11._bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._se_reduce.weight: copying a param with shape torch.Size([20, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for _blocks.11._se_reduce.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for _blocks.11._se_expand.weight: copying a param with shape torch.Size([480, 20, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for _blocks.11._se_expand.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._project_conv.weight: copying a param with shape torch.Size([80, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 672, 1, 1]).\n\tsize mismatch for _blocks.11._bn2.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.11._bn2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.11._bn2.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.11._bn2.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.12._expand_conv.weight: copying a param with shape torch.Size([480, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for _blocks.12._bn0.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn0.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn0.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn0.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._depthwise_conv.weight: copying a param with shape torch.Size([480, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for _blocks.12._bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._se_reduce.weight: copying a param with shape torch.Size([20, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for _blocks.12._se_reduce.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for _blocks.12._se_expand.weight: copying a param with shape torch.Size([480, 20, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for _blocks.12._se_expand.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._project_conv.weight: copying a param with shape torch.Size([112, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for _blocks.12._bn2.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.12._bn2.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.12._bn2.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.12._bn2.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.13._expand_conv.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for _blocks.13._bn0.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn0.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn0.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn0.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._depthwise_conv.weight: copying a param with shape torch.Size([672, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for _blocks.13._bn1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._se_reduce.weight: copying a param with shape torch.Size([28, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for _blocks.13._se_reduce.bias: copying a param with shape torch.Size([28]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for _blocks.13._se_expand.weight: copying a param with shape torch.Size([672, 28, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for _blocks.13._se_expand.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._project_conv.weight: copying a param with shape torch.Size([112, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for _blocks.13._bn2.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.13._bn2.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.13._bn2.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.13._bn2.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.14._expand_conv.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for _blocks.14._bn0.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn0.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn0.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn0.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._depthwise_conv.weight: copying a param with shape torch.Size([672, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for _blocks.14._bn1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._se_reduce.weight: copying a param with shape torch.Size([28, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for _blocks.14._se_reduce.bias: copying a param with shape torch.Size([28]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for _blocks.14._se_expand.weight: copying a param with shape torch.Size([672, 28, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for _blocks.14._se_expand.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._project_conv.weight: copying a param with shape torch.Size([112, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for _blocks.14._bn2.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.14._bn2.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.14._bn2.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.14._bn2.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.15._expand_conv.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for _blocks.15._bn0.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn0.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn0.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn0.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._depthwise_conv.weight: copying a param with shape torch.Size([672, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 3, 3]).\n\tsize mismatch for _blocks.15._bn1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._se_reduce.weight: copying a param with shape torch.Size([28, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for _blocks.15._se_reduce.bias: copying a param with shape torch.Size([28]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for _blocks.15._se_expand.weight: copying a param with shape torch.Size([672, 28, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for _blocks.15._se_expand.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._project_conv.weight: copying a param with shape torch.Size([112, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([320, 1152, 1, 1]).\n\tsize mismatch for _blocks.15._bn2.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for _blocks.15._bn2.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for _blocks.15._bn2.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for _blocks.15._bn2.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([320]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-500add1df844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfnm_mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{p_out}/model_{param.PRFX}_fld_{param.FLD2USE}_best.p'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfnm_mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnm_mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/mel/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"_blocks.1._expand_conv.weight\", \"_blocks.1._bn0.weight\", \"_blocks.1._bn0.bias\", \"_blocks.1._bn0.running_mean\", \"_blocks.1._bn0.running_var\", \"_avg_pooling.p\". \n\tUnexpected key(s) in state_dict: \"_blocks.16._expand_conv.weight\", \"_blocks.16._bn0.weight\", \"_blocks.16._bn0.bias\", \"_blocks.16._bn0.running_mean\", \"_blocks.16._bn0.running_var\", \"_blocks.16._bn0.num_batches_tracked\", \"_blocks.16._depthwise_conv.weight\", \"_blocks.16._bn1.weight\", \"_blocks.16._bn1.bias\", \"_blocks.16._bn1.running_mean\", \"_blocks.16._bn1.running_var\", \"_blocks.16._bn1.num_batches_tracked\", \"_blocks.16._se_reduce.weight\", \"_blocks.16._se_reduce.bias\", \"_blocks.16._se_expand.weight\", \"_blocks.16._se_expand.bias\", \"_blocks.16._project_conv.weight\", \"_blocks.16._bn2.weight\", \"_blocks.16._bn2.bias\", \"_blocks.16._bn2.running_mean\", \"_blocks.16._bn2.running_var\", \"_blocks.16._bn2.num_batches_tracked\", \"_blocks.17._expand_conv.weight\", \"_blocks.17._bn0.weight\", \"_blocks.17._bn0.bias\", \"_blocks.17._bn0.running_mean\", \"_blocks.17._bn0.running_var\", \"_blocks.17._bn0.num_batches_tracked\", \"_blocks.17._depthwise_conv.weight\", \"_blocks.17._bn1.weight\", \"_blocks.17._bn1.bias\", \"_blocks.17._bn1.running_mean\", \"_blocks.17._bn1.running_var\", \"_blocks.17._bn1.num_batches_tracked\", \"_blocks.17._se_reduce.weight\", \"_blocks.17._se_reduce.bias\", \"_blocks.17._se_expand.weight\", \"_blocks.17._se_expand.bias\", \"_blocks.17._project_conv.weight\", \"_blocks.17._bn2.weight\", \"_blocks.17._bn2.bias\", \"_blocks.17._bn2.running_mean\", \"_blocks.17._bn2.running_var\", \"_blocks.17._bn2.num_batches_tracked\", \"_blocks.18._expand_conv.weight\", \"_blocks.18._bn0.weight\", \"_blocks.18._bn0.bias\", \"_blocks.18._bn0.running_mean\", \"_blocks.18._bn0.running_var\", \"_blocks.18._bn0.num_batches_tracked\", \"_blocks.18._depthwise_conv.weight\", \"_blocks.18._bn1.weight\", \"_blocks.18._bn1.bias\", \"_blocks.18._bn1.running_mean\", \"_blocks.18._bn1.running_var\", \"_blocks.18._bn1.num_batches_tracked\", \"_blocks.18._se_reduce.weight\", \"_blocks.18._se_reduce.bias\", \"_blocks.18._se_expand.weight\", \"_blocks.18._se_expand.bias\", \"_blocks.18._project_conv.weight\", \"_blocks.18._bn2.weight\", \"_blocks.18._bn2.bias\", \"_blocks.18._bn2.running_mean\", \"_blocks.18._bn2.running_var\", \"_blocks.18._bn2.num_batches_tracked\", \"_blocks.19._expand_conv.weight\", \"_blocks.19._bn0.weight\", \"_blocks.19._bn0.bias\", \"_blocks.19._bn0.running_mean\", \"_blocks.19._bn0.running_var\", \"_blocks.19._bn0.num_batches_tracked\", \"_blocks.19._depthwise_conv.weight\", \"_blocks.19._bn1.weight\", \"_blocks.19._bn1.bias\", \"_blocks.19._bn1.running_mean\", \"_blocks.19._bn1.running_var\", \"_blocks.19._bn1.num_batches_tracked\", \"_blocks.19._se_reduce.weight\", \"_blocks.19._se_reduce.bias\", \"_blocks.19._se_expand.weight\", \"_blocks.19._se_expand.bias\", \"_blocks.19._project_conv.weight\", \"_blocks.19._bn2.weight\", \"_blocks.19._bn2.bias\", \"_blocks.19._bn2.running_mean\", \"_blocks.19._bn2.running_var\", \"_blocks.19._bn2.num_batches_tracked\", \"_blocks.20._expand_conv.weight\", \"_blocks.20._bn0.weight\", \"_blocks.20._bn0.bias\", \"_blocks.20._bn0.running_mean\", \"_blocks.20._bn0.running_var\", \"_blocks.20._bn0.num_batches_tracked\", \"_blocks.20._depthwise_conv.weight\", \"_blocks.20._bn1.weight\", \"_blocks.20._bn1.bias\", \"_blocks.20._bn1.running_mean\", \"_blocks.20._bn1.running_var\", \"_blocks.20._bn1.num_batches_tracked\", \"_blocks.20._se_reduce.weight\", \"_blocks.20._se_reduce.bias\", \"_blocks.20._se_expand.weight\", \"_blocks.20._se_expand.bias\", \"_blocks.20._project_conv.weight\", \"_blocks.20._bn2.weight\", \"_blocks.20._bn2.bias\", \"_blocks.20._bn2.running_mean\", \"_blocks.20._bn2.running_var\", \"_blocks.20._bn2.num_batches_tracked\", \"_blocks.21._expand_conv.weight\", \"_blocks.21._bn0.weight\", \"_blocks.21._bn0.bias\", \"_blocks.21._bn0.running_mean\", \"_blocks.21._bn0.running_var\", \"_blocks.21._bn0.num_batches_tracked\", \"_blocks.21._depthwise_conv.weight\", \"_blocks.21._bn1.weight\", \"_blocks.21._bn1.bias\", \"_blocks.21._bn1.running_mean\", \"_blocks.21._bn1.running_var\", \"_blocks.21._bn1.num_batches_tracked\", \"_blocks.21._se_reduce.weight\", \"_blocks.21._se_reduce.bias\", \"_blocks.21._se_expand.weight\", \"_blocks.21._se_expand.bias\", \"_blocks.21._project_conv.weight\", \"_blocks.21._bn2.weight\", \"_blocks.21._bn2.bias\", \"_blocks.21._bn2.running_mean\", \"_blocks.21._bn2.running_var\", \"_blocks.21._bn2.num_batches_tracked\", \"_blocks.22._expand_conv.weight\", \"_blocks.22._bn0.weight\", \"_blocks.22._bn0.bias\", \"_blocks.22._bn0.running_mean\", \"_blocks.22._bn0.running_var\", \"_blocks.22._bn0.num_batches_tracked\", \"_blocks.22._depthwise_conv.weight\", \"_blocks.22._bn1.weight\", \"_blocks.22._bn1.bias\", \"_blocks.22._bn1.running_mean\", \"_blocks.22._bn1.running_var\", \"_blocks.22._bn1.num_batches_tracked\", \"_blocks.22._se_reduce.weight\", \"_blocks.22._se_reduce.bias\", \"_blocks.22._se_expand.weight\", \"_blocks.22._se_expand.bias\", \"_blocks.22._project_conv.weight\", \"_blocks.22._bn2.weight\", \"_blocks.22._bn2.bias\", \"_blocks.22._bn2.running_mean\", \"_blocks.22._bn2.running_var\", \"_blocks.22._bn2.num_batches_tracked\". \n\tsize mismatch for _blocks.1._depthwise_conv.weight: copying a param with shape torch.Size([16, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 1, 3, 3]).\n\tsize mismatch for _blocks.1._bn1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for _blocks.1._bn1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for _blocks.1._bn1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for _blocks.1._bn1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for _blocks.1._se_reduce.weight: copying a param with shape torch.Size([4, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([4, 96, 1, 1]).\n\tsize mismatch for _blocks.1._se_expand.weight: copying a param with shape torch.Size([16, 4, 1, 1]) from checkpoint, the shape in current model is torch.Size([96, 4, 1, 1]).\n\tsize mismatch for _blocks.1._se_expand.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for _blocks.1._project_conv.weight: copying a param with shape torch.Size([16, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([24, 96, 1, 1]).\n\tsize mismatch for _blocks.1._bn2.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for _blocks.1._bn2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for _blocks.1._bn2.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for _blocks.1._bn2.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([24]).\n\tsize mismatch for _blocks.2._expand_conv.weight: copying a param with shape torch.Size([96, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([144, 24, 1, 1]).\n\tsize mismatch for _blocks.2._bn0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn0.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn0.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._depthwise_conv.weight: copying a param with shape torch.Size([96, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([144, 1, 3, 3]).\n\tsize mismatch for _blocks.2._bn1.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn1.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._bn1.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._se_reduce.weight: copying a param with shape torch.Size([4, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([6, 144, 1, 1]).\n\tsize mismatch for _blocks.2._se_reduce.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([6]).\n\tsize mismatch for _blocks.2._se_expand.weight: copying a param with shape torch.Size([96, 4, 1, 1]) from checkpoint, the shape in current model is torch.Size([144, 6, 1, 1]).\n\tsize mismatch for _blocks.2._se_expand.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([144]).\n\tsize mismatch for _blocks.2._project_conv.weight: copying a param with shape torch.Size([24, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([24, 144, 1, 1]).\n\tsize mismatch for _blocks.3._depthwise_conv.weight: copying a param with shape torch.Size([144, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([144, 1, 5, 5]).\n\tsize mismatch for _blocks.3._project_conv.weight: copying a param with shape torch.Size([24, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 144, 1, 1]).\n\tsize mismatch for _blocks.3._bn2.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.3._bn2.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.3._bn2.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.3._bn2.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.4._expand_conv.weight: copying a param with shape torch.Size([144, 24, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 40, 1, 1]).\n\tsize mismatch for _blocks.4._bn0.weight: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn0.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn0.running_mean: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn0.running_var: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._depthwise_conv.weight: copying a param with shape torch.Size([144, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 1, 5, 5]).\n\tsize mismatch for _blocks.4._bn1.weight: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn1.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn1.running_mean: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._bn1.running_var: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._se_reduce.weight: copying a param with shape torch.Size([6, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 240, 1, 1]).\n\tsize mismatch for _blocks.4._se_reduce.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([10]).\n\tsize mismatch for _blocks.4._se_expand.weight: copying a param with shape torch.Size([144, 6, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 10, 1, 1]).\n\tsize mismatch for _blocks.4._se_expand.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.4._project_conv.weight: copying a param with shape torch.Size([24, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 240, 1, 1]).\n\tsize mismatch for _blocks.4._bn2.weight: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.4._bn2.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.4._bn2.running_mean: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.4._bn2.running_var: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for _blocks.5._expand_conv.weight: copying a param with shape torch.Size([144, 24, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 40, 1, 1]).\n\tsize mismatch for _blocks.5._bn0.weight: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn0.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn0.running_mean: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn0.running_var: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._depthwise_conv.weight: copying a param with shape torch.Size([144, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([240, 1, 3, 3]).\n\tsize mismatch for _blocks.5._bn1.weight: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn1.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn1.running_mean: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._bn1.running_var: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._se_reduce.weight: copying a param with shape torch.Size([6, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([10, 240, 1, 1]).\n\tsize mismatch for _blocks.5._se_reduce.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([10]).\n\tsize mismatch for _blocks.5._se_expand.weight: copying a param with shape torch.Size([144, 6, 1, 1]) from checkpoint, the shape in current model is torch.Size([240, 10, 1, 1]).\n\tsize mismatch for _blocks.5._se_expand.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for _blocks.5._project_conv.weight: copying a param with shape torch.Size([40, 144, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 240, 1, 1]).\n\tsize mismatch for _blocks.5._bn2.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.5._bn2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.5._bn2.running_mean: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.5._bn2.running_var: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.6._expand_conv.weight: copying a param with shape torch.Size([240, 40, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for _blocks.6._bn0.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn0.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn0.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn0.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._depthwise_conv.weight: copying a param with shape torch.Size([240, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([480, 1, 3, 3]).\n\tsize mismatch for _blocks.6._bn1.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn1.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn1.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._bn1.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._se_reduce.weight: copying a param with shape torch.Size([10, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for _blocks.6._se_reduce.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for _blocks.6._se_expand.weight: copying a param with shape torch.Size([240, 10, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for _blocks.6._se_expand.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.6._project_conv.weight: copying a param with shape torch.Size([40, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 480, 1, 1]).\n\tsize mismatch for _blocks.6._bn2.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.6._bn2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.6._bn2.running_mean: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.6._bn2.running_var: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.7._expand_conv.weight: copying a param with shape torch.Size([240, 40, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for _blocks.7._bn0.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn0.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn0.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn0.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._depthwise_conv.weight: copying a param with shape torch.Size([240, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([480, 1, 3, 3]).\n\tsize mismatch for _blocks.7._bn1.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn1.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn1.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._bn1.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._se_reduce.weight: copying a param with shape torch.Size([10, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for _blocks.7._se_reduce.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for _blocks.7._se_expand.weight: copying a param with shape torch.Size([240, 10, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for _blocks.7._se_expand.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.7._project_conv.weight: copying a param with shape torch.Size([40, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([80, 480, 1, 1]).\n\tsize mismatch for _blocks.7._bn2.weight: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.7._bn2.bias: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.7._bn2.running_mean: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.7._bn2.running_var: copying a param with shape torch.Size([40]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for _blocks.8._expand_conv.weight: copying a param with shape torch.Size([240, 40, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 80, 1, 1]).\n\tsize mismatch for _blocks.8._bn0.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn0.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn0.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn0.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._depthwise_conv.weight: copying a param with shape torch.Size([240, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([480, 1, 5, 5]).\n\tsize mismatch for _blocks.8._bn1.weight: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn1.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn1.running_mean: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._bn1.running_var: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._se_reduce.weight: copying a param with shape torch.Size([10, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 480, 1, 1]).\n\tsize mismatch for _blocks.8._se_reduce.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for _blocks.8._se_expand.weight: copying a param with shape torch.Size([240, 10, 1, 1]) from checkpoint, the shape in current model is torch.Size([480, 20, 1, 1]).\n\tsize mismatch for _blocks.8._se_expand.bias: copying a param with shape torch.Size([240]) from checkpoint, the shape in current model is torch.Size([480]).\n\tsize mismatch for _blocks.8._project_conv.weight: copying a param with shape torch.Size([80, 240, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 480, 1, 1]).\n\tsize mismatch for _blocks.8._bn2.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.8._bn2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.8._bn2.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.8._bn2.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.9._expand_conv.weight: copying a param with shape torch.Size([480, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for _blocks.9._bn0.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn0.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn0.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn0.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._depthwise_conv.weight: copying a param with shape torch.Size([480, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for _blocks.9._bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._se_reduce.weight: copying a param with shape torch.Size([20, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for _blocks.9._se_reduce.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for _blocks.9._se_expand.weight: copying a param with shape torch.Size([480, 20, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for _blocks.9._se_expand.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.9._project_conv.weight: copying a param with shape torch.Size([80, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 672, 1, 1]).\n\tsize mismatch for _blocks.9._bn2.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.9._bn2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.9._bn2.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.9._bn2.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.10._expand_conv.weight: copying a param with shape torch.Size([480, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for _blocks.10._bn0.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn0.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn0.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn0.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._depthwise_conv.weight: copying a param with shape torch.Size([480, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for _blocks.10._bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._se_reduce.weight: copying a param with shape torch.Size([20, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for _blocks.10._se_reduce.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for _blocks.10._se_expand.weight: copying a param with shape torch.Size([480, 20, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for _blocks.10._se_expand.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.10._project_conv.weight: copying a param with shape torch.Size([80, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([112, 672, 1, 1]).\n\tsize mismatch for _blocks.10._bn2.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.10._bn2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.10._bn2.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.10._bn2.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([112]).\n\tsize mismatch for _blocks.11._expand_conv.weight: copying a param with shape torch.Size([480, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 112, 1, 1]).\n\tsize mismatch for _blocks.11._bn0.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn0.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn0.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn0.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._depthwise_conv.weight: copying a param with shape torch.Size([480, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([672, 1, 5, 5]).\n\tsize mismatch for _blocks.11._bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._se_reduce.weight: copying a param with shape torch.Size([20, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([28, 672, 1, 1]).\n\tsize mismatch for _blocks.11._se_reduce.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([28]).\n\tsize mismatch for _blocks.11._se_expand.weight: copying a param with shape torch.Size([480, 20, 1, 1]) from checkpoint, the shape in current model is torch.Size([672, 28, 1, 1]).\n\tsize mismatch for _blocks.11._se_expand.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([672]).\n\tsize mismatch for _blocks.11._project_conv.weight: copying a param with shape torch.Size([80, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 672, 1, 1]).\n\tsize mismatch for _blocks.11._bn2.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.11._bn2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.11._bn2.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.11._bn2.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.12._expand_conv.weight: copying a param with shape torch.Size([480, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for _blocks.12._bn0.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn0.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn0.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn0.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._depthwise_conv.weight: copying a param with shape torch.Size([480, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for _blocks.12._bn1.weight: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn1.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn1.running_mean: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._bn1.running_var: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._se_reduce.weight: copying a param with shape torch.Size([20, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for _blocks.12._se_reduce.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for _blocks.12._se_expand.weight: copying a param with shape torch.Size([480, 20, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for _blocks.12._se_expand.bias: copying a param with shape torch.Size([480]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.12._project_conv.weight: copying a param with shape torch.Size([112, 480, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for _blocks.12._bn2.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.12._bn2.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.12._bn2.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.12._bn2.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.13._expand_conv.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for _blocks.13._bn0.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn0.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn0.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn0.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._depthwise_conv.weight: copying a param with shape torch.Size([672, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for _blocks.13._bn1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._bn1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._se_reduce.weight: copying a param with shape torch.Size([28, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for _blocks.13._se_reduce.bias: copying a param with shape torch.Size([28]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for _blocks.13._se_expand.weight: copying a param with shape torch.Size([672, 28, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for _blocks.13._se_expand.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.13._project_conv.weight: copying a param with shape torch.Size([112, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for _blocks.13._bn2.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.13._bn2.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.13._bn2.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.13._bn2.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.14._expand_conv.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for _blocks.14._bn0.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn0.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn0.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn0.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._depthwise_conv.weight: copying a param with shape torch.Size([672, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 5, 5]).\n\tsize mismatch for _blocks.14._bn1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._bn1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._se_reduce.weight: copying a param with shape torch.Size([28, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for _blocks.14._se_reduce.bias: copying a param with shape torch.Size([28]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for _blocks.14._se_expand.weight: copying a param with shape torch.Size([672, 28, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for _blocks.14._se_expand.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.14._project_conv.weight: copying a param with shape torch.Size([112, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 1152, 1, 1]).\n\tsize mismatch for _blocks.14._bn2.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.14._bn2.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.14._bn2.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.14._bn2.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for _blocks.15._expand_conv.weight: copying a param with shape torch.Size([672, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 192, 1, 1]).\n\tsize mismatch for _blocks.15._bn0.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn0.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn0.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn0.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._depthwise_conv.weight: copying a param with shape torch.Size([672, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([1152, 1, 3, 3]).\n\tsize mismatch for _blocks.15._bn1.weight: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn1.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn1.running_mean: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._bn1.running_var: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._se_reduce.weight: copying a param with shape torch.Size([28, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1152, 1, 1]).\n\tsize mismatch for _blocks.15._se_reduce.bias: copying a param with shape torch.Size([28]) from checkpoint, the shape in current model is torch.Size([48]).\n\tsize mismatch for _blocks.15._se_expand.weight: copying a param with shape torch.Size([672, 28, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 48, 1, 1]).\n\tsize mismatch for _blocks.15._se_expand.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).\n\tsize mismatch for _blocks.15._project_conv.weight: copying a param with shape torch.Size([112, 672, 1, 1]) from checkpoint, the shape in current model is torch.Size([320, 1152, 1, 1]).\n\tsize mismatch for _blocks.15._bn2.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for _blocks.15._bn2.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for _blocks.15._bn2.running_mean: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for _blocks.15._bn2.running_var: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([320])."
     ]
    }
   ],
   "source": [
    "mdl = mkmdl()\n",
    "fnm_mdl = f'{p_out}/model_{param.PRFX}_fld_{param.FLD2USE}_best.p'\n",
    "print('load model', fnm_mdl)\n",
    "mdl.load_state_dict(torch.load(fnm_mdl, map_location=torch.device(DEVICE)))\n",
    "\n",
    "mdl = mdl.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, dl):\n",
    "    lendl=len(dl)\n",
    "    model.eval()\n",
    "    prd = []\n",
    "    for step, dat in enumerate(dl):\n",
    "        if step%1000==0: print(dtnow(), f'step {step}/{lendl}')\n",
    "        xb=dat[0].to(device)\n",
    "        with torch.no_grad(): prdb = model(xb)\n",
    "        prd.append(prdb.cpu().detach().numpy())\n",
    "    prd = np.concatenate(prd)    \n",
    "    return prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'infer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2c98b818d0a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprdtst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdltst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'infer' is not defined"
     ]
    }
   ],
   "source": [
    "prdtst = infer(mdl, dltst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prdtst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-df7f665ef9ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfsub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprdtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfsub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdfsub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prdtst' is not defined"
     ]
    }
   ],
   "source": [
    "dfsub.target = sigmoid(prdtst)\n",
    "print(dfsub.target.mean())\n",
    "dfsub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dfsub.target, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub.to_csv(f'{p_out}/submission_{param.PRFX}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'best_scr {best_scr:.4f}; best_epc {best_epc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mel",
   "language": "python",
   "name": "mel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
