{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mainly looking at https://github.com/ngessert/isic2019/blob/master/models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param: pass\n",
    "param = Param()\n",
    "\n",
    "param.PRFX = 'Mel0626A5'\n",
    "param.PRFX_PREP = 'MelPrp0626A2'\n",
    "param.ARCH = 'efficientnet-b0'\n",
    "param.SZ = 128\n",
    "param.EPOCHS = 10\n",
    "param.BS = 512\n",
    "param.K=5; param.SEED=101; param.FLD2USE=0\n",
    "param.FP16 = False\n",
    "\n",
    "param.LR=1e-6\n",
    "param.MOMENTUM=0.9\n",
    "param.WD=0.\n",
    "\n",
    "param.N_SAMPL = int(5e3)\n",
    "\n",
    "param.DEBUG = False\n",
    "if param.DEBUG: \n",
    "    param.EPOCHS=2\n",
    "    param.K = 2\n",
    "    param.N_SAMPL = 512\n",
    "\n",
    "DEVICE = 'cuda'; PIN_MEM = (DEVICE=='cuda'); N_WORKERS=4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRFX': 'Mel0626A5',\n",
       " 'PRFX_PREP': 'MelPrp0626A2',\n",
       " 'ARCH': 'efficientnet-b0',\n",
       " 'SZ': 128,\n",
       " 'EPOCHS': 10,\n",
       " 'BS': 512,\n",
       " 'K': 5,\n",
       " 'SEED': 101,\n",
       " 'FLD2USE': 0,\n",
       " 'FP16': False,\n",
       " 'LR': 1e-06,\n",
       " 'MOMENTUM': 0.9,\n",
       " 'WD': 0.0,\n",
       " 'N_SAMPL': 5000,\n",
       " 'DEBUG': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 27 02:45:23 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   46C    P0    32W / 300W |     11MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os, sys, gc\n",
    "import datetime\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score as roc_auc\n",
    "from sklearn.metrics import accuracy_score as acuuracy\n",
    "\n",
    "# https://github.com/eriklindernoren/PyTorch-YOLOv3/issues/162#issuecomment-491115265\n",
    "from PIL import ImageFile; ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "import torch\n",
    "device=torch.device(DEVICE)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "set_seed(param.SEED)\n",
    "\n",
    "\n",
    "\n",
    "p_out=f'../output/{param.PRFX}'; Path(p_out).mkdir(exist_ok=True,parents=True)\n",
    "# p_cmp = '../input/siim-isic-melanoma-classification'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58457, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>im_pth</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24437</th>\n",
       "      <td>20</td>\n",
       "      <td>../input/siim-isic-melanoma-classification/jpe...</td>\n",
       "      <td>IP_4021847</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57432</th>\n",
       "      <td>19</td>\n",
       "      <td>../input/andrewmvd--isic-2019/ISIC_2019_Traini...</td>\n",
       "      <td>BCN_0004730</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                             im_pth   patient_id  \\\n",
       "24437      20  ../input/siim-isic-melanoma-classification/jpe...   IP_4021847   \n",
       "57432      19  ../input/andrewmvd--isic-2019/ISIC_2019_Traini...  BCN_0004730   \n",
       "\n",
       "       target  \n",
       "24437     0.0  \n",
       "57432     1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    2780\n",
       "19    2220\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "19    0.191892\n",
       "20    0.016906\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train,test,sample_submission = (pd.read_csv(o, nrows=100 if DEBUG else None) \n",
    "#                                 for o in [f'{p_cmp}/{o}.csv' \n",
    "#                                           for o in ('train', 'test', 'sample_submission')])\n",
    "# print([o.shape for o in (train,test,sample_submission)])\n",
    "# display(test.head(2))\n",
    "# p_19 = '../input/andrewmvd--isic-2019'\n",
    "\n",
    "p_prp = f'../output/{param.PRFX_PREP}'\n",
    "dftrn = pd.read_csv(f'{p_prp}/train_all.csv') \n",
    "print(dftrn.shape)\n",
    "\n",
    "set_seed(param.SEED); dftrn = dftrn.sample(frac=1.)\n",
    "\n",
    "if param.N_SAMPL is not None: dftrn = dftrn.head(param.N_SAMPL)\n",
    "    \n",
    "display(dftrn.head(2))\n",
    "display(dftrn.shape)\n",
    "display(dftrn.source.value_counts())\n",
    "display(dftrn.groupby('source').target.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "idx_nopid=np.where(dftrn.patient_id.isna())[0]\n",
    "print(len(idx_nopid))\n",
    "dftrn['patient_id'].iloc[idx_nopid]=[f'Nan_{i}' for i in range(len(idx_nopid))]\n",
    "assert dftrn.patient_id.isna().mean()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4000 1000\n",
      "1 4000 1000\n",
      "2 4000 1000\n",
      "3 4000 1000\n",
      "4 4000 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.90475\n",
       "1.0    0.09525\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.9015\n",
       "1.0    0.0985\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.90875\n",
       "1.0    0.09125\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.90825\n",
       "1.0    0.09175\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.90375\n",
       "1.0    0.09625\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    2221\n",
       "19    1779\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    2196\n",
       "19    1804\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    2240\n",
       "19    1760\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    2231\n",
       "19    1769\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    2232\n",
       "19    1768\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(param.SEED)\n",
    "kf = GroupKFold(n_splits=param.K)\n",
    "fld2trvl={fld:(tr,vl) for fld,(tr,vl) in enumerate(kf.split(dftrn, groups=dftrn.patient_id))}\n",
    "\n",
    "for fld, (tr, vl) in fld2trvl.items():\n",
    "    print(fld, len(tr), len(vl))\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    dfvl=dftrn.iloc[vl]\n",
    "    assert set(dftr.patient_id)&set(dfvl.patient_id)==set()\n",
    "for fld, (tr, vl) in fld2trvl.items():\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    display(dftr.target.value_counts()/len(tr))\n",
    "for fld, (tr, vl) in fld2trvl.items():\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    display(dftr.source.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 ms, sys: 453 µs, total: 11.3 ms\n",
      "Wall time: 17.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "im_pil = Image.open(dftrn.im_pth.sample().values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1189.26it/s]\n"
     ]
    }
   ],
   "source": [
    "ims_pil = []\n",
    "for im_pth in tqdm(dftrn.im_pth):\n",
    "    ims_pil.append(Image.open(im_pth))\n",
    "### faster to preload images\n",
    "# i = np.random.choice(range(len(dftrn)))\n",
    "# %%timeit \n",
    "# im_pil = Image.open(dftrn.im_pth.values[i])\n",
    "# %%timeit \n",
    "# im_pil = ims_pil[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(Dataset):\n",
    "    def __init__(self, imgs, targets=None):\n",
    "        self.imgs = imgs\n",
    "        self.targets = targets\n",
    "        self.composed = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(param.SZ),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ColorJitter(brightness=32. / 255.,saturation=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])    \n",
    "    def __getitem__(self, i):\n",
    "        x = self.imgs[i]\n",
    "        x = self.composed(x)\n",
    "        if self.targets is not None:\n",
    "            y = self.targets[i]\n",
    "            return x, y\n",
    "        else:\n",
    "            return x,\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_trn = MelDataset(ims_pil, dftrn.target.values)\n",
    "# ds_trn[0][0].shape, ds_trn[0][1]\n",
    "\n",
    "# plt.imshow(ds_trn[0][0].numpy().transpose(1,2,0));\n",
    "# plt.show()\n",
    "\n",
    "# dl_trn = DataLoader(ds_trn, batch_size=BS, shuffle=True, num_workers=4, pin_memory=PIN_MEM)\n",
    "# for dat in dl_trn:\n",
    "#     x,y=dat; break\n",
    "\n",
    "# print(x.shape, y)\n",
    "\n",
    "# del ds_trn; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mdl = EfficientNet.from_pretrained(ARCH, num_classes=1)\n",
    "# mdl(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1000\n",
      "4000 1000\n",
      "8 1\n"
     ]
    }
   ],
   "source": [
    "tr,vl=fld2trvl[param.FLD2USE]\n",
    "dftr=dftrn.iloc[tr]\n",
    "dfvl=dftrn.iloc[vl]\n",
    "ystr=dftr.target.values\n",
    "ysvl=dfvl.target.values\n",
    "print(len(dftr), len(dfvl))\n",
    "dstr = MelDataset([ims_pil[o] for o in tr], ystr)\n",
    "dsvl = MelDataset([ims_pil[o] for o in vl], ysvl)\n",
    "print(len(dstr), len(dsvl))\n",
    "dltr = DataLoader(dstr, batch_size=param.BS,   shuffle=True,  num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "dlvl = DataLoader(dsvl, batch_size=param.BS*2, shuffle=False, num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "print(len(dltr), len(dlvl))\n",
    "lendl=len(dltr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ys, model, dl):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        prd = []\n",
    "        for step, batch in enumerate(dl):\n",
    "            xb, yb=(o.to(device) for o in batch)\n",
    "            prdb = model(xb)\n",
    "            prd.append(prdb.cpu().detach().numpy())\n",
    "        prd = np.concatenate(prd)    \n",
    "        lss = F.binary_cross_entropy_with_logits(torch.tensor(prd),torch.tensor(ys).unsqueeze(1)).item()\n",
    "        scr = roc_auc(ys, prd)\n",
    "    return lss, scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "mdl = EfficientNet.from_pretrained(param.ARCH, num_classes=1)\n",
    "mdl = mdl.to(device)\n",
    "\n",
    "opt = optim.SGD(mdl.parameters(), lr=param.LR, momentum=param.MOMENTUM, weight_decay=param.WD)\n",
    "# schdl = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=PLTFACTOR, patience=PATIENCE, min_lr=MIN_LR, verbose=True)\n",
    "\n",
    "mdl, opt = amp.initialize(mdl, opt, opt_level='O1', verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    'lss': {'tr':[],'vl':[]},\n",
    "    'scr': {'tr':[],'vl':[]},\n",
    "}\n",
    "best_scr = float('-inf')\n",
    "best_epc = -1\n",
    "for epc in range(param.EPOCHS):\n",
    "    prdtr_ep=[]\n",
    "    ytr_ep=[]\n",
    "    for step, dat in enumerate(dltr):\n",
    "        mdl.train()\n",
    "        xb,yb=(o.to(device) for o in dat)\n",
    "        yb=yb.unsqueeze(1)\n",
    "        prdb = mdl(xb)\n",
    "        loss = F.binary_cross_entropy_with_logits(prdb, yb)\n",
    "        if param.FP16:\n",
    "            with amp.scale_loss(loss, opt) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        if param.FP16:\n",
    "            torch.nn.utils.clip_grad_norm_(amp.master_params(opt), 1)\n",
    "        else:\n",
    "            torch.nn.utils.clip_grad_norm_(mdl.parameters(), 1)\n",
    "        opt.step()\n",
    "        mdl.zero_grad()\n",
    "        prdtr_ep.append(prdb.cpu().detach().numpy())\n",
    "        ytr_ep.append(yb.cpu().detach().numpy())\n",
    "        if step%1000==0: \n",
    "            print(dtnow(), f'ep {epc} step {step}/{lendl}')\n",
    "    \n",
    "    prdtr_ep = np.concatenate(prdtr_ep)\n",
    "    ytr_ep = np.concatenate(ytr_ep)    \n",
    "    lss_tr_ep = F.binary_cross_entropy_with_logits(torch.tensor(prdtr_ep),torch.tensor(ytr_ep)).item()\n",
    "    scr_tr_ep = roc_auc(ytr_ep, prdtr_ep)\n",
    "    stats['lss']['tr'].append(lss_tr_ep)\n",
    "    stats['scr']['tr'].append(scr_tr_ep)\n",
    "    \n",
    "    lss_vl_ep, scr_vl_ep = evaluate(ysvl, mdl, dlvl)\n",
    "    stats['lss']['vl'].append(lss_vl_ep)\n",
    "    stats['scr']['vl'].append(scr_vl_ep)\n",
    "    print(dtnow(), f'ep {epc}: lss_tr {lss_tr_ep:.3f}; lss_vl {lss_vl_ep:.3f}; scr_tr {scr_tr_ep:.3f}; scr_vl {scr_vl_ep:.3f}; ')\n",
    "    \n",
    "    if scr_vl_ep>best_scr:\n",
    "        print(f'better scr {best_scr:.3f} -> {scr_vl_ep:.3f}')\n",
    "        best_scr = scr_vl_ep\n",
    "        best_epc = epc\n",
    "        torch.save(mdl.state_dict(), f'{p_out}/model_{param.PRFX}_fld_{fld}_best.p')\n",
    "    torch.save(mdl.state_dict(), f'{p_out}/model_{param.PRFX}_fld_{fld}_epc_{epc}.p')\n",
    "        \n",
    "#     schdl.step(lossval)  # Update learning rate schedule\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'best_scr {best_scr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(stats['lss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(stats['scr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in stats.items():\n",
    "    for tv,vs in v.items():\n",
    "        plt.title(f'{k} {tv}')\n",
    "        plt.plot(vs, 'o--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['best_scr'] = best_scr\n",
    "stats['best_epc'] = best_epc\n",
    "\n",
    "results = {}\n",
    "results['fld2trvl']=fld2trvl\n",
    "results['stats'] = stats\n",
    "\n",
    "pickle.dump(results, open(f'{p_out}/results.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(param, open(f'{p_out}/param.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'best_scr {best_scr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mel",
   "language": "python",
   "name": "mel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
