{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pseudo label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRFX': 'Mel0712B1',\n",
       " 'PRFX_B4': None,\n",
       " 'FLD2USE_B4': 0,\n",
       " 'PRFX_PREP': 'MelPrp0909B384',\n",
       " 'ARCH': 'efficientnet-b0',\n",
       " 'SZ': 224,\n",
       " 'EPOCHS': 30,\n",
       " 'BS': 176,\n",
       " 'SEED': 101,\n",
       " 'K': 5,\n",
       " 'FLDS2USE': range(0, 5),\n",
       " 'FP16': True,\n",
       " 'PLTFACTOR': 0.5,\n",
       " 'PATIENCE': 3,\n",
       " 'MIN_LR': 1e-08,\n",
       " 'USE_LAST_M_EPCS': 5,\n",
       " 'RandomResizedCrop_scale': (0.75, 1.0),\n",
       " 'N_TTA': 8,\n",
       " 'LR': 0.001,\n",
       " 'WD': 0,\n",
       " 'N_SAMPL': None,\n",
       " 'DEBUG': False}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Param: pass\n",
    "param = Param()\n",
    "\n",
    "#########################\n",
    "param.PRFX = 'Mel0712B1'#\n",
    "#########################\n",
    "\n",
    "param.PRFX_B4 = None; param.FLD2USE_B4 = 0\n",
    "param.PRFX_PREP = 'MelPrp0909B384' \n",
    "param.ARCH = 'efficientnet-b0'\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "param.SZ = 224 \n",
    "\n",
    "param.EPOCHS = 30\n",
    "\n",
    "param.BS = 176\n",
    "param.SEED = 101; \n",
    "\n",
    "param.K=5; \n",
    "param.FLDS2USE = range(param.K)\n",
    "param.FP16 = True\n",
    "param.PLTFACTOR=0.5; param.PATIENCE=3; param.MIN_LR=1e-8\n",
    "\n",
    "param.USE_LAST_M_EPCS = 5\n",
    "\n",
    "param.RandomResizedCrop_scale=(0.75, 1.0)\n",
    "param.N_TTA = 8\n",
    "\n",
    "param.LR=1e-3\n",
    "param.WD=0\n",
    "\n",
    "param.N_SAMPL = None\n",
    "\n",
    "param.DEBUG = False\n",
    "if param.DEBUG: \n",
    "    param.EPOCHS = 2\n",
    "    param.FLDS2USE = [0,1]\n",
    "    param.N_SAMPL = 1024\n",
    "\n",
    "DEVICE = 'cuda'; \n",
    "if DEVICE=='cpu': param.FP16 = False\n",
    "PIN_MEM = (DEVICE=='cuda'); N_WORKERS=4\n",
    "\n",
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 13 03:14:35 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   64C    P0   170W / 300W |   6358MiB / 16160MiB |     98%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     11607      C   /data/anaconda3/envs/mel/bin/python         6343MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os, sys, gc\n",
    "import datetime\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score as roc_auc\n",
    "\n",
    "# https://github.com/eriklindernoren/PyTorch-YOLOv3/issues/162#issuecomment-491115265\n",
    "from PIL import ImageFile; ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def dtnow(): return datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "import torch\n",
    "device=torch.device(DEVICE)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import pretrainedmodels\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations import pytorch as AT\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "set_seed(param.SEED)\n",
    "\n",
    "\n",
    "\n",
    "p_out = f'../output/{param.PRFX}'; Path(p_out).mkdir(exist_ok=True,parents=True)\n",
    "p_cmp = '../input/siim-isic-melanoma-classification'\n",
    "if param.PRFX_B4 is not None: p_b4  = f'../output/{param.PRFX_B4}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58032, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>im_pth</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23539</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "      <td>IP_2618037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48725</th>\n",
       "      <td>19</td>\n",
       "      <td>../output/MelPrp0909B384/andrewmvd--isic-2019/...</td>\n",
       "      <td>BCN_0000529</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                             im_pth   patient_id  \\\n",
       "23539      20  ../output/MelPrp0909B384/siim-isic-melanoma-cl...   IP_2618037   \n",
       "48725      19  ../output/MelPrp0909B384/andrewmvd--isic-2019/...  BCN_0000529   \n",
       "\n",
       "       target  \n",
       "23539     0.0  \n",
       "48725     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(58032, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    32701\n",
       "19    25331\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "19    0.178516\n",
       "20    0.017767\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_prp = f'../output/{param.PRFX_PREP}'\n",
    "dftrn = pd.read_csv(f'{p_prp}/train_all_dedup.csv') \n",
    "print(dftrn.shape)\n",
    "\n",
    "set_seed(param.SEED); dftrn = dftrn.sample(frac=1.)\n",
    "\n",
    "if param.N_SAMPL is not None: dftrn = dftrn.head(param.N_SAMPL)\n",
    "    \n",
    "display(dftrn.head(2))\n",
    "display(dftrn.shape)\n",
    "display(dftrn.source.value_counts())\n",
    "display(dftrn.groupby('source').target.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2084\n"
     ]
    }
   ],
   "source": [
    "idx_nopid=np.where(dftrn.patient_id.isna())[0]\n",
    "print(len(idx_nopid))\n",
    "dftrn['patient_id'].iloc[idx_nopid]=[f'Nan_{i}' for i in range(len(idx_nopid))]\n",
    "assert dftrn.patient_id.isna().mean()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 46425 11607\n",
      "1 46425 11607\n",
      "2 46426 11606\n",
      "3 46426 11606\n",
      "4 46426 11606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.912159\n",
       "1.0    0.087841\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.911922\n",
       "1.0    0.088078\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.911903\n",
       "1.0    0.088097\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.910697\n",
       "1.0    0.089303\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.913648\n",
       "1.0    0.086352\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26172\n",
       "19    20253\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26147\n",
       "19    20278\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26171\n",
       "19    20255\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26137\n",
       "19    20289\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20    26177\n",
       "19    20249\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(param.SEED)\n",
    "kf = GroupKFold(n_splits=param.K)\n",
    "fld2trvl=list(kf.split(dftrn, groups=dftrn.patient_id))\n",
    "\n",
    "for fld, (tr, vl) in enumerate(fld2trvl):\n",
    "    print(fld, len(tr), len(vl))\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    dfvl=dftrn.iloc[vl]\n",
    "    assert set(dftr.patient_id)&set(dfvl.patient_id)==set()\n",
    "for fld, (tr, vl) in enumerate(fld2trvl):\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    display(dftr.target.value_counts()/len(tr))\n",
    "for fld, (tr, vl) in enumerate(fld2trvl):\n",
    "    dftr=dftrn.iloc[tr]\n",
    "    display(dftr.source.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    32701\n",
       "19    25331\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "32701"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(dftrn.source.value_counts())\n",
    "idx20 = np.where(dftrn.source==20)[0]\n",
    "len(idx20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11607 6529\n",
      "11607 6554\n",
      "11606 6530\n",
      "11606 6564\n",
      "11606 6524\n"
     ]
    }
   ],
   "source": [
    "fld2vl20 = []\n",
    "for tr, vl in fld2trvl:\n",
    "    vl20 = np.array([o for o in vl if o in idx20])\n",
    "    print(len(vl), len(vl20))\n",
    "    fld2vl20.append(vl20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>im_pth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>IP_3579794</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>IP_7782715</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>IP_7960270</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_0052060  IP_3579794    male        70.0                           NaN   \n",
       "1  ISIC_0052349  IP_7782715    male        40.0               lower extremity   \n",
       "2  ISIC_0058510  IP_7960270  female        55.0                         torso   \n",
       "\n",
       "                                              im_pth  \n",
       "0  ../output/MelPrp0909B384/siim-isic-melanoma-cl...  \n",
       "1  ../output/MelPrp0909B384/siim-isic-melanoma-cl...  \n",
       "2  ../output/MelPrp0909B384/siim-isic-melanoma-cl...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftst = pd.read_csv(f'{p_prp}/test.csv', nrows=128 if param.DEBUG else None) \n",
    "display(dftst.head(3))\n",
    "\n",
    "dfsub = pd.read_csv(f'{p_cmp}/sample_submission.csv', nrows=128 if param.DEBUG else None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pseudo label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "      <th>im_pth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.452031</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.200596</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.165812</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target                                             im_pth\n",
       "0  ISIC_0052060  0.452031  ../output/MelPrp0909B384/siim-isic-melanoma-cl...\n",
       "1  ISIC_0052349  0.200596  ../output/MelPrp0909B384/siim-isic-melanoma-cl...\n",
       "2  ISIC_0058510  0.165812  ../output/MelPrp0909B384/siim-isic-melanoma-cl..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpsd=pd.read_csv('../output/public_subs/ragnar123:rank-then-blend:v2:lb946/blend_sub.csv')\n",
    "dfpsd['im_pth'] = dftst.im_pth\n",
    "dfpsd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutsize=param.SZ//10\n",
    "class MelDataset(Dataset):\n",
    "    def __init__(self, df, mode='trn'):\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        if mode=='trn':\n",
    "            self.composed = A.Compose([\n",
    "                A.RandomResizedCrop(param.SZ,param.SZ, scale=param.RandomResizedCrop_scale),\n",
    "                A.Transpose(),\n",
    "                A.Flip(),\n",
    "                A.Rotate(360),\n",
    "                A.OneOf([A.RandomBrightnessContrast(), A.CLAHE(),]),\n",
    "#                 A.HueSaturationValue(\n",
    "#                     hue_shift_limit=5,\n",
    "#                     sat_shift_limit=5,\n",
    "#                     p=1),\n",
    "#                 A.OneOf([\n",
    "#                     A.Cutout(num_holes=8, max_h_size=cutsize, max_w_size=cutsize),\n",
    "#                     A.GridDropout(),]),\n",
    "                A.Normalize(), \n",
    "                AT.ToTensor(),\n",
    "            ])    \n",
    "        else:\n",
    "            self.composed = A.Compose([\n",
    "                A.Resize(param.SZ, param.SZ),\n",
    "                A.Normalize(),\n",
    "                AT.ToTensor(),\n",
    "            ])    \n",
    "    def __getitem__(self, i):\n",
    "        x = cv2.imread(self.df.im_pth.values[i]) \n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "        x = self.composed(image=x)['image']\n",
    "        if self.mode in ('trn', 'val'):\n",
    "            y = self.df.target.values[i]\n",
    "            return x, y\n",
    "        else:\n",
    "            return (x,)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better comment out A.Normalize() when showing \n",
    "if param.DEBUG:\n",
    "    dstrn = MelDataset(dftrn, mode='trn')\n",
    "    i = np.random.choice(len(dstrn))\n",
    "    print(dstrn[i][0].shape)\n",
    "    plt.imshow(dstrn[i][0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10982\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "dstst = MelDataset(dftst, mode='tst')\n",
    "print(len(dstst))\n",
    "dltst = DataLoader(dstst, batch_size=param.BS*2, shuffle=False, num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "print(len(dltst))\n",
    "lendl=len(dltst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkmdl():  \n",
    "    mdl = EfficientNet.from_pretrained(param.ARCH, num_classes=1)\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "mdl = mkmdl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1., gamma=3, logits=True, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    return FocalLoss()(outputs, targets.view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, dl):\n",
    "#     model.eval()\n",
    "#     prd = []\n",
    "#     y = []\n",
    "#     for step, dat in enumerate(dl):\n",
    "#         xb, yb = (o.to(device) for o in dat)\n",
    "#         with torch.no_grad(): prdb = model(xb)\n",
    "#         prd.append(prdb.cpu().detach().numpy())\n",
    "#         y.append(yb.cpu().detach().numpy())\n",
    "#     prd = np.concatenate(prd)    \n",
    "#     y = np.concatenate(y)    \n",
    "#     lss = F.binary_cross_entropy_with_logits(torch.tensor(prd),torch.tensor(y).unsqueeze(1)).item()\n",
    "#     scr = roc_auc(y, prd)\n",
    "#     return lss, scr, y, prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diheral TTA outside dataloader\n",
    "def get_trans(img, I):\n",
    "    if I >= 4:\n",
    "        img = img.transpose(2,3)\n",
    "    if I % 4 == 0:\n",
    "        return img\n",
    "    elif I % 4 == 1:\n",
    "        return img.flip(2)\n",
    "    elif I % 4 == 2:\n",
    "        return img.flip(3)\n",
    "    elif I % 4 == 3:\n",
    "        return img.flip(2).flip(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    prd = []\n",
    "    y = []   \n",
    "    for step, dat in enumerate(dl):\n",
    "        xb, yb = (o.to(device) for o in dat)\n",
    "        y.append(yb.cpu().detach().numpy())\n",
    "        with torch.no_grad(): \n",
    "            for I in range(param.N_TTA):\n",
    "                if I==0: \n",
    "                    prdb = model(get_trans(xb, I))\n",
    "                else:\n",
    "                    prdb += model(get_trans(xb, I))    \n",
    "        prd.append((prdb/param.N_TTA).cpu().detach().numpy())\n",
    "    prd = np.concatenate(prd)    \n",
    "    y = np.concatenate(y)    \n",
    "    lss = F.binary_cross_entropy_with_logits(torch.tensor(prd),torch.tensor(y).unsqueeze(1)).item()\n",
    "    scr = roc_auc(y, prd)\n",
    "    return lss, scr, y, prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, dl):\n",
    "    lendl=len(dl)\n",
    "    model.eval()\n",
    "    prd = []\n",
    "    for step, dat in enumerate(dl):\n",
    "        if step>0 and step%1000==0: print(dtnow(), f'step {step}/{lendl}')\n",
    "        xb=dat[0].to(device)\n",
    "        with torch.no_grad(): \n",
    "            for I in range(param.N_TTA):\n",
    "                if I==0: \n",
    "                    prdb = model(get_trans(xb, I))\n",
    "                else:\n",
    "                    prdb += model(get_trans(xb, I))    \n",
    "        prd.append((prdb/param.N_TTA).cpu().detach().numpy())\n",
    "    prd = np.concatenate(prd)    \n",
    "\n",
    "    return prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>im_pth</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23539</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "      <td>IP_2618037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48725</th>\n",
       "      <td>19</td>\n",
       "      <td>../output/MelPrp0909B384/andrewmvd--isic-2019/...</td>\n",
       "      <td>BCN_0000529</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29254</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "      <td>IP_0921705</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26654</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "      <td>IP_3621895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25602</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "      <td>IP_3240837</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "      <td>IP_4488328</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8006</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "      <td>IP_3739659</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17745</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "      <td>IP_6945048</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17931</th>\n",
       "      <td>20</td>\n",
       "      <td>../output/MelPrp0909B384/siim-isic-melanoma-cl...</td>\n",
       "      <td>IP_8011614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45919</th>\n",
       "      <td>19</td>\n",
       "      <td>../output/MelPrp0909B384/andrewmvd--isic-2019/...</td>\n",
       "      <td>BCN_0004669</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58032 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                             im_pth   patient_id  \\\n",
       "23539      20  ../output/MelPrp0909B384/siim-isic-melanoma-cl...   IP_2618037   \n",
       "48725      19  ../output/MelPrp0909B384/andrewmvd--isic-2019/...  BCN_0000529   \n",
       "29254      20  ../output/MelPrp0909B384/siim-isic-melanoma-cl...   IP_0921705   \n",
       "26654      20  ../output/MelPrp0909B384/siim-isic-melanoma-cl...   IP_3621895   \n",
       "25602      20  ../output/MelPrp0909B384/siim-isic-melanoma-cl...   IP_3240837   \n",
       "...       ...                                                ...          ...   \n",
       "5695       20  ../output/MelPrp0909B384/siim-isic-melanoma-cl...   IP_4488328   \n",
       "8006       20  ../output/MelPrp0909B384/siim-isic-melanoma-cl...   IP_3739659   \n",
       "17745      20  ../output/MelPrp0909B384/siim-isic-melanoma-cl...   IP_6945048   \n",
       "17931      20  ../output/MelPrp0909B384/siim-isic-melanoma-cl...   IP_8011614   \n",
       "45919      19  ../output/MelPrp0909B384/andrewmvd--isic-2019/...  BCN_0004669   \n",
       "\n",
       "       target  \n",
       "23539     0.0  \n",
       "48725     0.0  \n",
       "29254     0.0  \n",
       "26654     0.0  \n",
       "25602     0.0  \n",
       "...       ...  \n",
       "5695      0.0  \n",
       "8006      0.0  \n",
       "17745     0.0  \n",
       "17931     0.0  \n",
       "45919     0.0  \n",
       "\n",
       "[58032 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdls(fld):\n",
    "    cols2use=['im_pth', 'target']\n",
    "    tr,vl=fld2trvl[fld]\n",
    "    vl20 =fld2vl20[fld]\n",
    "    assert set(vl20) < set(vl)\n",
    "    dftr=pd.concat([dftrn[cols2use].iloc[tr], dfpsd[cols2use]])\n",
    "    dfvl=dftrn.iloc[vl]\n",
    "    dfvl20=dftrn.iloc[vl20]\n",
    "    ystr=dftr.target.values\n",
    "    ysvl=dfvl.target.values\n",
    "    ysvl20=dfvl20.target.values\n",
    "    dstr = MelDataset(dftr, mode='trn')\n",
    "    dsvl = MelDataset(dfvl, mode='val')\n",
    "    dsvl20 = MelDataset(dfvl20, mode='val')\n",
    "    dltr = DataLoader(dstr, batch_size=param.BS,       shuffle=True,  num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "    dlvl = DataLoader(dsvl, batch_size=param.BS*2,     shuffle=False, num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "    dlvl20 = DataLoader(dsvl20, batch_size=param.BS*2, shuffle=False, num_workers=N_WORKERS, pin_memory=PIN_MEM)\n",
    "    lendl=len(dltr)    \n",
    "    return dltr,dlvl,dlvl20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "fld:0; dltr,dlvl,dlvl20: 327 33 19\n",
      "2020-07-13 03:22:47 fld 0 ep 0: lss_tr 0.489; lss_vl 0.374; lss_vl20 0.312; scr_tr 0.782; scr_vl 0.870; scr_vl20 0.887; \n",
      "better scr -inf -> 0.870\n",
      "better scr20 -inf -> 0.887\n",
      "2020-07-13 03:28:38 fld 0 ep 1: lss_tr 0.472; lss_vl 0.443; lss_vl20 0.407; scr_tr 0.821; scr_vl 0.802; scr_vl20 0.875; \n",
      "2020-07-13 03:36:24 fld 0 ep 2: lss_tr 0.466; lss_vl 0.411; lss_vl20 0.365; scr_tr 0.836; scr_vl 0.877; scr_vl20 0.912; \n",
      "better scr 0.870 -> 0.877\n",
      "better scr20 0.887 -> 0.912\n",
      "2020-07-13 03:44:20 fld 0 ep 3: lss_tr 0.459; lss_vl 0.394; lss_vl20 0.352; scr_tr 0.845; scr_vl 0.864; scr_vl20 0.913; \n",
      "better scr20 0.912 -> 0.913\n",
      "2020-07-13 03:50:11 fld 0 ep 4: lss_tr 0.454; lss_vl 0.391; lss_vl20 0.349; scr_tr 0.854; scr_vl 0.871; scr_vl20 0.905; \n",
      "2020-07-13 03:57:54 fld 0 ep 5: lss_tr 0.450; lss_vl 0.384; lss_vl20 0.338; scr_tr 0.859; scr_vl 0.855; scr_vl20 0.913; \n",
      "better scr20 0.913 -> 0.913\n",
      "2020-07-13 04:05:51 fld 0 ep 6: lss_tr 0.444; lss_vl 0.396; lss_vl20 0.365; scr_tr 0.867; scr_vl 0.842; scr_vl20 0.914; \n",
      "better scr20 0.913 -> 0.914\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-04.\n",
      "2020-07-13 04:12:34 fld 0 ep 7: lss_tr 0.430; lss_vl 0.400; lss_vl20 0.368; scr_tr 0.886; scr_vl 0.880; scr_vl20 0.926; \n",
      "better scr 0.877 -> 0.880\n",
      "better scr20 0.914 -> 0.926\n",
      "2020-07-13 04:22:01 fld 0 ep 8: lss_tr 0.423; lss_vl 0.374; lss_vl20 0.340; scr_tr 0.894; scr_vl 0.873; scr_vl20 0.928; \n",
      "better scr20 0.926 -> 0.928\n",
      "2020-07-13 04:32:26 fld 0 ep 9: lss_tr 0.416; lss_vl 0.374; lss_vl20 0.341; scr_tr 0.899; scr_vl 0.848; scr_vl20 0.929; \n",
      "better scr20 0.928 -> 0.929\n",
      "2020-07-13 04:39:09 fld 0 ep 10: lss_tr 0.413; lss_vl 0.379; lss_vl20 0.344; scr_tr 0.902; scr_vl 0.855; scr_vl20 0.926; \n",
      "2020-07-13 04:47:28 fld 0 ep 11: lss_tr 0.406; lss_vl 0.389; lss_vl20 0.368; scr_tr 0.907; scr_vl 0.868; scr_vl20 0.924; \n",
      "Epoch    12: reducing learning rate of group 0 to 2.5000e-04.\n",
      "2020-07-13 04:59:02 fld 0 ep 12: lss_tr 0.389; lss_vl 0.365; lss_vl20 0.341; scr_tr 0.922; scr_vl 0.845; scr_vl20 0.929; \n",
      "better scr20 0.929 -> 0.929\n",
      "2020-07-13 05:05:46 fld 0 ep 13: lss_tr 0.383; lss_vl 0.367; lss_vl20 0.353; scr_tr 0.928; scr_vl 0.818; scr_vl20 0.930; \n",
      "better scr20 0.929 -> 0.930\n",
      "2020-07-13 05:12:58 fld 0 ep 14: lss_tr 0.375; lss_vl 0.364; lss_vl20 0.349; scr_tr 0.932; scr_vl 0.817; scr_vl20 0.930; \n",
      "better scr20 0.930 -> 0.930\n",
      "2020-07-13 05:24:45 fld 0 ep 15: lss_tr 0.370; lss_vl 0.347; lss_vl20 0.321; scr_tr 0.935; scr_vl 0.789; scr_vl20 0.940; \n",
      "better scr20 0.930 -> 0.940\n",
      "Epoch    16: reducing learning rate of group 0 to 1.2500e-04.\n",
      "2020-07-13 05:32:19 fld 0 ep 16: lss_tr 0.361; lss_vl 0.353; lss_vl20 0.336; scr_tr 0.942; scr_vl 0.815; scr_vl20 0.936; \n",
      "2020-07-13 05:39:00 fld 0 ep 17: lss_tr 0.354; lss_vl 0.348; lss_vl20 0.331; scr_tr 0.947; scr_vl 0.801; scr_vl20 0.937; \n",
      "2020-07-13 05:50:07 fld 0 ep 18: lss_tr 0.352; lss_vl 0.357; lss_vl20 0.344; scr_tr 0.947; scr_vl 0.789; scr_vl20 0.932; \n",
      "2020-07-13 05:58:54 fld 0 ep 19: lss_tr 0.347; lss_vl 0.352; lss_vl20 0.331; scr_tr 0.950; scr_vl 0.797; scr_vl20 0.936; \n",
      "Epoch    20: reducing learning rate of group 0 to 6.2500e-05.\n",
      "2020-07-13 06:05:38 fld 0 ep 20: lss_tr 0.341; lss_vl 0.351; lss_vl20 0.333; scr_tr 0.954; scr_vl 0.798; scr_vl20 0.931; \n",
      "2020-07-13 06:15:34 fld 0 ep 21: lss_tr 0.336; lss_vl 0.351; lss_vl20 0.335; scr_tr 0.957; scr_vl 0.784; scr_vl20 0.926; \n",
      "2020-07-13 06:25:29 fld 0 ep 22: lss_tr 0.333; lss_vl 0.351; lss_vl20 0.334; scr_tr 0.957; scr_vl 0.776; scr_vl20 0.934; \n",
      "2020-07-13 06:32:11 fld 0 ep 23: lss_tr 0.329; lss_vl 0.348; lss_vl20 0.330; scr_tr 0.960; scr_vl 0.780; scr_vl20 0.930; \n",
      "Epoch    24: reducing learning rate of group 0 to 3.1250e-05.\n",
      "2020-07-13 06:40:57 fld 0 ep 24: lss_tr 0.327; lss_vl 0.349; lss_vl20 0.332; scr_tr 0.961; scr_vl 0.781; scr_vl20 0.929; \n",
      "2020-07-13 06:52:08 fld 0 ep 25: lss_tr 0.326; lss_vl 0.347; lss_vl20 0.331; scr_tr 0.961; scr_vl 0.789; scr_vl20 0.929; \n",
      "2020-07-13 06:58:51 fld 0 ep 26: lss_tr 0.325; lss_vl 0.351; lss_vl20 0.335; scr_tr 0.962; scr_vl 0.781; scr_vl20 0.930; \n",
      "2020-07-13 07:06:25 fld 0 ep 27: lss_tr 0.324; lss_vl 0.343; lss_vl20 0.322; scr_tr 0.963; scr_vl 0.778; scr_vl20 0.930; \n",
      "Epoch    28: reducing learning rate of group 0 to 1.5625e-05.\n",
      "2020-07-13 07:18:12 fld 0 ep 28: lss_tr 0.319; lss_vl 0.349; lss_vl20 0.330; scr_tr 0.965; scr_vl 0.773; scr_vl20 0.928; \n",
      "2020-07-13 07:25:20 fld 0 ep 29: lss_tr 0.320; lss_vl 0.347; lss_vl20 0.328; scr_tr 0.964; scr_vl 0.774; scr_vl20 0.926; \n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "fld:1; dltr,dlvl,dlvl20: 327 33 19\n",
      "2020-07-13 07:32:06 fld 1 ep 0: lss_tr 0.490; lss_vl 0.422; lss_vl20 0.370; scr_tr 0.778; scr_vl 0.886; scr_vl20 0.881; \n",
      "better scr -inf -> 0.886\n",
      "better scr20 -inf -> 0.881\n",
      "2020-07-13 07:42:22 fld 1 ep 1: lss_tr 0.475; lss_vl 0.349; lss_vl20 0.280; scr_tr 0.819; scr_vl 0.892; scr_vl20 0.903; \n",
      "better scr 0.886 -> 0.892\n",
      "better scr20 0.881 -> 0.903\n",
      "2020-07-13 07:50:21 fld 1 ep 2: lss_tr 0.466; lss_vl 0.398; lss_vl20 0.343; scr_tr 0.832; scr_vl 0.898; scr_vl20 0.903; \n",
      "better scr 0.892 -> 0.898\n",
      "better scr20 0.903 -> 0.903\n",
      "2020-07-13 07:56:15 fld 1 ep 3: lss_tr 0.461; lss_vl 0.436; lss_vl20 0.413; scr_tr 0.842; scr_vl 0.891; scr_vl20 0.902; \n",
      "2020-07-13 08:04:08 fld 1 ep 4: lss_tr 0.456; lss_vl 0.385; lss_vl20 0.338; scr_tr 0.850; scr_vl 0.882; scr_vl20 0.897; \n",
      "2020-07-13 08:14:29 fld 1 ep 5: lss_tr 0.451; lss_vl 0.403; lss_vl20 0.369; scr_tr 0.859; scr_vl 0.897; scr_vl20 0.911; \n",
      "better scr20 0.903 -> 0.911\n",
      "2020-07-13 08:20:22 fld 1 ep 6: lss_tr 0.446; lss_vl 0.418; lss_vl20 0.388; scr_tr 0.865; scr_vl 0.891; scr_vl20 0.901; \n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-04.\n",
      "2020-07-13 08:27:14 fld 1 ep 7: lss_tr 0.431; lss_vl 0.378; lss_vl20 0.350; scr_tr 0.884; scr_vl 0.901; scr_vl20 0.930; \n",
      "better scr 0.898 -> 0.901\n",
      "better scr20 0.911 -> 0.930\n",
      "2020-07-13 08:39:04 fld 1 ep 8: lss_tr 0.423; lss_vl 0.364; lss_vl20 0.345; scr_tr 0.893; scr_vl 0.890; scr_vl20 0.921; \n",
      "2020-07-13 08:47:00 fld 1 ep 9: lss_tr 0.417; lss_vl 0.347; lss_vl20 0.323; scr_tr 0.898; scr_vl 0.895; scr_vl20 0.922; \n",
      "2020-07-13 08:53:45 fld 1 ep 10: lss_tr 0.412; lss_vl 0.368; lss_vl20 0.370; scr_tr 0.903; scr_vl 0.835; scr_vl20 0.918; \n",
      "2020-07-13 09:04:35 fld 1 ep 11: lss_tr 0.408; lss_vl 0.352; lss_vl20 0.336; scr_tr 0.906; scr_vl 0.880; scr_vl20 0.913; \n",
      "Epoch    12: reducing learning rate of group 0 to 2.5000e-04.\n",
      "2020-07-13 09:13:39 fld 1 ep 12: lss_tr 0.390; lss_vl 0.341; lss_vl20 0.325; scr_tr 0.921; scr_vl 0.870; scr_vl20 0.924; \n",
      "2020-07-13 09:20:24 fld 1 ep 13: lss_tr 0.382; lss_vl 0.343; lss_vl20 0.332; scr_tr 0.926; scr_vl 0.859; scr_vl20 0.921; \n",
      "2020-07-13 09:29:22 fld 1 ep 14: lss_tr 0.376; lss_vl 0.339; lss_vl20 0.328; scr_tr 0.931; scr_vl 0.867; scr_vl20 0.907; \n",
      "2020-07-13 09:32:56 fld 1 ep 15: lss_tr 0.372; lss_vl 0.342; lss_vl20 0.328; scr_tr 0.934; scr_vl 0.878; scr_vl20 0.913; \n",
      "Epoch    16: reducing learning rate of group 0 to 1.2500e-04.\n",
      "2020-07-13 09:36:30 fld 1 ep 16: lss_tr 0.363; lss_vl 0.339; lss_vl20 0.333; scr_tr 0.941; scr_vl 0.855; scr_vl20 0.912; \n",
      "2020-07-13 09:40:03 fld 1 ep 17: lss_tr 0.354; lss_vl 0.341; lss_vl20 0.340; scr_tr 0.945; scr_vl 0.861; scr_vl20 0.909; \n",
      "2020-07-13 09:43:36 fld 1 ep 18: lss_tr 0.353; lss_vl 0.336; lss_vl20 0.335; scr_tr 0.947; scr_vl 0.858; scr_vl20 0.906; \n",
      "2020-07-13 09:47:08 fld 1 ep 19: lss_tr 0.348; lss_vl 0.333; lss_vl20 0.334; scr_tr 0.950; scr_vl 0.839; scr_vl20 0.902; \n",
      "Epoch    20: reducing learning rate of group 0 to 6.2500e-05.\n",
      "2020-07-13 09:50:40 fld 1 ep 20: lss_tr 0.341; lss_vl 0.325; lss_vl20 0.324; scr_tr 0.954; scr_vl 0.846; scr_vl20 0.898; \n",
      "2020-07-13 09:54:14 fld 1 ep 21: lss_tr 0.335; lss_vl 0.327; lss_vl20 0.326; scr_tr 0.956; scr_vl 0.837; scr_vl20 0.897; \n",
      "2020-07-13 09:57:47 fld 1 ep 22: lss_tr 0.334; lss_vl 0.329; lss_vl20 0.330; scr_tr 0.956; scr_vl 0.842; scr_vl20 0.893; \n",
      "2020-07-13 10:01:20 fld 1 ep 23: lss_tr 0.331; lss_vl 0.335; lss_vl20 0.338; scr_tr 0.959; scr_vl 0.836; scr_vl20 0.896; \n",
      "Epoch    24: reducing learning rate of group 0 to 3.1250e-05.\n",
      "2020-07-13 10:04:54 fld 1 ep 24: lss_tr 0.329; lss_vl 0.331; lss_vl20 0.332; scr_tr 0.959; scr_vl 0.834; scr_vl20 0.895; \n",
      "2020-07-13 10:08:28 fld 1 ep 25: lss_tr 0.328; lss_vl 0.329; lss_vl20 0.331; scr_tr 0.961; scr_vl 0.830; scr_vl20 0.893; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-13 10:12:02 fld 1 ep 26: lss_tr 0.325; lss_vl 0.322; lss_vl20 0.319; scr_tr 0.961; scr_vl 0.836; scr_vl20 0.896; \n",
      "2020-07-13 10:15:36 fld 1 ep 27: lss_tr 0.323; lss_vl 0.329; lss_vl20 0.331; scr_tr 0.963; scr_vl 0.825; scr_vl20 0.889; \n",
      "Epoch    28: reducing learning rate of group 0 to 1.5625e-05.\n",
      "2020-07-13 10:19:09 fld 1 ep 28: lss_tr 0.322; lss_vl 0.327; lss_vl20 0.327; scr_tr 0.963; scr_vl 0.830; scr_vl20 0.890; \n",
      "2020-07-13 10:22:43 fld 1 ep 29: lss_tr 0.321; lss_vl 0.325; lss_vl20 0.324; scr_tr 0.964; scr_vl 0.826; scr_vl20 0.887; \n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "fld:2; dltr,dlvl,dlvl20: 327 33 19\n",
      "2020-07-13 10:26:19 fld 2 ep 0: lss_tr 0.491; lss_vl 0.409; lss_vl20 0.359; scr_tr 0.780; scr_vl 0.890; scr_vl20 0.884; \n",
      "better scr -inf -> 0.890\n",
      "better scr20 -inf -> 0.884\n",
      "2020-07-13 10:29:23 fld 2 ep 1: lss_tr 0.477; lss_vl 0.425; lss_vl20 0.396; scr_tr 0.812; scr_vl 0.884; scr_vl20 0.880; \n",
      "2020-07-13 10:32:28 fld 2 ep 2: lss_tr 0.469; lss_vl 0.425; lss_vl20 0.376; scr_tr 0.830; scr_vl 0.915; scr_vl20 0.893; \n",
      "better scr 0.890 -> 0.915\n",
      "better scr20 0.884 -> 0.893\n",
      "2020-07-13 10:35:32 fld 2 ep 3: lss_tr 0.463; lss_vl 0.364; lss_vl20 0.319; scr_tr 0.839; scr_vl 0.900; scr_vl20 0.899; \n",
      "better scr20 0.893 -> 0.899\n",
      "2020-07-13 10:38:37 fld 2 ep 4: lss_tr 0.459; lss_vl 0.383; lss_vl20 0.338; scr_tr 0.847; scr_vl 0.920; scr_vl20 0.906; \n",
      "better scr 0.915 -> 0.920\n",
      "better scr20 0.899 -> 0.906\n",
      "2020-07-13 10:41:41 fld 2 ep 5: lss_tr 0.453; lss_vl 0.328; lss_vl20 0.268; scr_tr 0.854; scr_vl 0.906; scr_vl20 0.880; \n",
      "2020-07-13 10:44:45 fld 2 ep 6: lss_tr 0.450; lss_vl 0.373; lss_vl20 0.325; scr_tr 0.859; scr_vl 0.898; scr_vl20 0.900; \n",
      "2020-07-13 10:48:21 fld 2 ep 7: lss_tr 0.446; lss_vl 0.384; lss_vl20 0.346; scr_tr 0.865; scr_vl 0.928; scr_vl20 0.916; \n",
      "better scr 0.920 -> 0.928\n",
      "better scr20 0.906 -> 0.916\n",
      "2020-07-13 10:51:56 fld 2 ep 8: lss_tr 0.442; lss_vl 0.375; lss_vl20 0.342; scr_tr 0.870; scr_vl 0.924; scr_vl20 0.915; \n",
      "2020-07-13 10:55:33 fld 2 ep 9: lss_tr 0.438; lss_vl 0.386; lss_vl20 0.362; scr_tr 0.877; scr_vl 0.910; scr_vl20 0.912; \n",
      "2020-07-13 10:59:10 fld 2 ep 10: lss_tr 0.435; lss_vl 0.387; lss_vl20 0.379; scr_tr 0.880; scr_vl 0.904; scr_vl20 0.917; \n",
      "better scr20 0.916 -> 0.917\n",
      "2020-07-13 11:02:47 fld 2 ep 11: lss_tr 0.429; lss_vl 0.396; lss_vl20 0.381; scr_tr 0.886; scr_vl 0.910; scr_vl20 0.918; \n",
      "better scr20 0.917 -> 0.918\n",
      "Epoch    12: reducing learning rate of group 0 to 5.0000e-04.\n",
      "2020-07-13 11:06:26 fld 2 ep 12: lss_tr 0.413; lss_vl 0.365; lss_vl20 0.350; scr_tr 0.902; scr_vl 0.905; scr_vl20 0.928; \n",
      "better scr20 0.918 -> 0.928\n",
      "2020-07-13 11:10:05 fld 2 ep 13: lss_tr 0.405; lss_vl 0.327; lss_vl20 0.316; scr_tr 0.909; scr_vl 0.896; scr_vl20 0.925; \n",
      "2020-07-13 11:13:43 fld 2 ep 14: lss_tr 0.399; lss_vl 0.343; lss_vl20 0.333; scr_tr 0.915; scr_vl 0.898; scr_vl20 0.924; \n",
      "2020-07-13 11:17:21 fld 2 ep 15: lss_tr 0.394; lss_vl 0.349; lss_vl20 0.340; scr_tr 0.918; scr_vl 0.899; scr_vl20 0.924; \n",
      "Epoch    16: reducing learning rate of group 0 to 2.5000e-04.\n",
      "2020-07-13 11:21:01 fld 2 ep 16: lss_tr 0.381; lss_vl 0.338; lss_vl20 0.337; scr_tr 0.928; scr_vl 0.898; scr_vl20 0.928; \n",
      "better scr20 0.928 -> 0.928\n",
      "2020-07-13 11:24:39 fld 2 ep 17: lss_tr 0.369; lss_vl 0.333; lss_vl20 0.341; scr_tr 0.935; scr_vl 0.899; scr_vl20 0.925; \n",
      "2020-07-13 11:28:14 fld 2 ep 18: lss_tr 0.365; lss_vl 0.335; lss_vl20 0.346; scr_tr 0.938; scr_vl 0.888; scr_vl20 0.929; \n",
      "better scr20 0.928 -> 0.929\n",
      "2020-07-13 11:31:49 fld 2 ep 19: lss_tr 0.360; lss_vl 0.342; lss_vl20 0.355; scr_tr 0.941; scr_vl 0.883; scr_vl20 0.927; \n",
      "Epoch    20: reducing learning rate of group 0 to 1.2500e-04.\n",
      "2020-07-13 11:35:24 fld 2 ep 20: lss_tr 0.351; lss_vl 0.326; lss_vl20 0.336; scr_tr 0.947; scr_vl 0.858; scr_vl20 0.923; \n",
      "2020-07-13 11:38:59 fld 2 ep 21: lss_tr 0.345; lss_vl 0.318; lss_vl20 0.323; scr_tr 0.949; scr_vl 0.862; scr_vl20 0.919; \n",
      "2020-07-13 11:42:34 fld 2 ep 22: lss_tr 0.344; lss_vl 0.325; lss_vl20 0.332; scr_tr 0.951; scr_vl 0.871; scr_vl20 0.927; \n",
      "2020-07-13 11:46:10 fld 2 ep 23: lss_tr 0.339; lss_vl 0.326; lss_vl20 0.336; scr_tr 0.954; scr_vl 0.855; scr_vl20 0.921; \n",
      "Epoch    24: reducing learning rate of group 0 to 6.2500e-05.\n",
      "2020-07-13 11:49:46 fld 2 ep 24: lss_tr 0.334; lss_vl 0.319; lss_vl20 0.328; scr_tr 0.956; scr_vl 0.859; scr_vl20 0.922; \n",
      "2020-07-13 11:53:21 fld 2 ep 25: lss_tr 0.332; lss_vl 0.321; lss_vl20 0.333; scr_tr 0.958; scr_vl 0.851; scr_vl20 0.917; \n",
      "2020-07-13 11:56:56 fld 2 ep 26: lss_tr 0.329; lss_vl 0.319; lss_vl20 0.332; scr_tr 0.959; scr_vl 0.841; scr_vl20 0.916; \n",
      "2020-07-13 12:00:36 fld 2 ep 27: lss_tr 0.328; lss_vl 0.321; lss_vl20 0.331; scr_tr 0.959; scr_vl 0.849; scr_vl20 0.914; \n",
      "Epoch    28: reducing learning rate of group 0 to 3.1250e-05.\n",
      "2020-07-13 12:04:10 fld 2 ep 28: lss_tr 0.326; lss_vl 0.318; lss_vl20 0.327; scr_tr 0.961; scr_vl 0.852; scr_vl20 0.912; \n",
      "2020-07-13 12:07:47 fld 2 ep 29: lss_tr 0.325; lss_vl 0.318; lss_vl20 0.327; scr_tr 0.961; scr_vl 0.852; scr_vl20 0.912; \n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "fld:3; dltr,dlvl,dlvl20: 327 33 19\n",
      "2020-07-13 12:11:28 fld 3 ep 0: lss_tr 0.487; lss_vl 0.407; lss_vl20 0.345; scr_tr 0.785; scr_vl 0.875; scr_vl20 0.866; \n",
      "better scr -inf -> 0.875\n",
      "better scr20 -inf -> 0.866\n",
      "2020-07-13 12:14:33 fld 3 ep 1: lss_tr 0.473; lss_vl 0.404; lss_vl20 0.348; scr_tr 0.822; scr_vl 0.876; scr_vl20 0.870; \n",
      "better scr 0.875 -> 0.876\n",
      "better scr20 0.866 -> 0.870\n",
      "2020-07-13 12:17:39 fld 3 ep 2: lss_tr 0.464; lss_vl 0.398; lss_vl20 0.357; scr_tr 0.839; scr_vl 0.880; scr_vl20 0.876; \n",
      "better scr 0.876 -> 0.880\n",
      "better scr20 0.870 -> 0.876\n",
      "2020-07-13 12:20:45 fld 3 ep 3: lss_tr 0.458; lss_vl 0.421; lss_vl20 0.386; scr_tr 0.848; scr_vl 0.888; scr_vl20 0.892; \n",
      "better scr 0.880 -> 0.888\n",
      "better scr20 0.876 -> 0.892\n",
      "2020-07-13 12:23:51 fld 3 ep 4: lss_tr 0.455; lss_vl 0.385; lss_vl20 0.331; scr_tr 0.855; scr_vl 0.871; scr_vl20 0.885; \n",
      "2020-07-13 12:26:57 fld 3 ep 5: lss_tr 0.450; lss_vl 0.362; lss_vl20 0.323; scr_tr 0.861; scr_vl 0.863; scr_vl20 0.875; \n",
      "2020-07-13 12:30:03 fld 3 ep 6: lss_tr 0.446; lss_vl 0.353; lss_vl20 0.305; scr_tr 0.866; scr_vl 0.890; scr_vl20 0.898; \n",
      "better scr 0.888 -> 0.890\n",
      "better scr20 0.892 -> 0.898\n",
      "2020-07-13 12:33:42 fld 3 ep 7: lss_tr 0.443; lss_vl 0.364; lss_vl20 0.332; scr_tr 0.871; scr_vl 0.862; scr_vl20 0.903; \n",
      "better scr20 0.898 -> 0.903\n",
      "2020-07-13 12:37:22 fld 3 ep 8: lss_tr 0.439; lss_vl 0.378; lss_vl20 0.336; scr_tr 0.876; scr_vl 0.896; scr_vl20 0.894; \n",
      "better scr 0.890 -> 0.896\n",
      "2020-07-13 12:41:01 fld 3 ep 9: lss_tr 0.432; lss_vl 0.384; lss_vl20 0.361; scr_tr 0.884; scr_vl 0.867; scr_vl20 0.900; \n",
      "2020-07-13 12:44:41 fld 3 ep 10: lss_tr 0.432; lss_vl 0.385; lss_vl20 0.345; scr_tr 0.884; scr_vl 0.893; scr_vl20 0.899; \n",
      "2020-07-13 12:48:21 fld 3 ep 11: lss_tr 0.427; lss_vl 0.377; lss_vl20 0.352; scr_tr 0.890; scr_vl 0.872; scr_vl20 0.880; \n",
      "2020-07-13 12:52:01 fld 3 ep 12: lss_tr 0.423; lss_vl 0.399; lss_vl20 0.385; scr_tr 0.893; scr_vl 0.831; scr_vl20 0.894; \n",
      "Epoch    13: reducing learning rate of group 0 to 5.0000e-04.\n",
      "2020-07-13 12:55:40 fld 3 ep 13: lss_tr 0.406; lss_vl 0.351; lss_vl20 0.338; scr_tr 0.911; scr_vl 0.859; scr_vl20 0.905; \n",
      "better scr20 0.903 -> 0.905\n",
      "2020-07-13 12:59:19 fld 3 ep 14: lss_tr 0.398; lss_vl 0.363; lss_vl20 0.354; scr_tr 0.916; scr_vl 0.855; scr_vl20 0.908; \n",
      "better scr20 0.905 -> 0.908\n",
      "2020-07-13 13:02:58 fld 3 ep 15: lss_tr 0.391; lss_vl 0.360; lss_vl20 0.348; scr_tr 0.921; scr_vl 0.848; scr_vl20 0.906; \n",
      "2020-07-13 13:06:36 fld 3 ep 16: lss_tr 0.387; lss_vl 0.360; lss_vl20 0.349; scr_tr 0.925; scr_vl 0.858; scr_vl20 0.910; \n",
      "better scr20 0.908 -> 0.910\n",
      "Epoch    17: reducing learning rate of group 0 to 2.5000e-04.\n",
      "2020-07-13 13:10:14 fld 3 ep 17: lss_tr 0.373; lss_vl 0.362; lss_vl20 0.359; scr_tr 0.934; scr_vl 0.838; scr_vl20 0.890; \n",
      "2020-07-13 13:13:52 fld 3 ep 18: lss_tr 0.367; lss_vl 0.359; lss_vl20 0.358; scr_tr 0.939; scr_vl 0.852; scr_vl20 0.897; \n"
     ]
    }
   ],
   "source": [
    "set_seed(param.SEED)\n",
    "\n",
    "results = {}\n",
    "results['fld2trvl'] = fld2trvl\n",
    "results['fld2vl20'] = fld2vl20\n",
    "results['param'] = param\n",
    "results['fld2stats']={}\n",
    "\n",
    "for fld in param.FLDS2USE:\n",
    "\n",
    "    mdl = mkmdl().to(device)\n",
    "    if param.PRFX_B4 is not None: \n",
    "        fnm_mdl_b4 = f'{p_b4}/model_{param.PRFX_B4}_fld_{param.fld}_best.p'\n",
    "        print('load previously trained', fnm_mdl_b4)\n",
    "        mdl.load_state_dict(torch.load(fnm_mdl_b4, map_location=torch.device(DEVICE)))\n",
    "    # opt = optim.SGD(mdl.parameters(), lr=param.LR, momentum=param.MOMENTUM, weight_decay=param.WD)\n",
    "    opt = optim.Adam(mdl.parameters(), lr=param.LR, weight_decay=param.WD)\n",
    "    schdl = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=param.PLTFACTOR, patience=param.PATIENCE, min_lr=param.MIN_LR, verbose=True)\n",
    "    if param.FP16: mdl, opt = amp.initialize(mdl, opt, opt_level='O1', verbosity=0)\n",
    "    mdl.zero_grad()\n",
    "\n",
    "        \n",
    "    tr,vl=fld2trvl[fld]\n",
    "    dltr,dlvl,dlvl20=getdls(fld)\n",
    "    print(f'fld:{fld};', 'dltr,dlvl,dlvl20:', len(dltr), len(dlvl),len(dlvl20))\n",
    "    \n",
    "\n",
    "    stats = {\n",
    "    'lss': {'tr':[],'vl':[],'vl20':[]},\n",
    "    'scr': {'tr':[],'vl':[],'vl20':[]},\n",
    "    }\n",
    "    ep2oof = []\n",
    "\n",
    "    best_scr = float('-inf')\n",
    "    best_epc = -1\n",
    "    best_scr20 = float('-inf')\n",
    "    best_epc20 = -1\n",
    "    \n",
    "    \n",
    "    for epc in range(param.EPOCHS):\n",
    "        prdtr_ep=[]\n",
    "        ytr_ep=[]\n",
    "        for step, dat in enumerate(dltr):\n",
    "            mdl.train()\n",
    "            xb,yb=(o.to(device) for o in dat)\n",
    "            yb = yb.unsqueeze(1)\n",
    "            prdb = mdl(xb)\n",
    "    #         loss = F.binary_cross_entropy_with_logits(prdb, yb)\n",
    "            loss =  loss_fn(prdb,yb)\n",
    "            if param.FP16:\n",
    "                with amp.scale_loss(loss, opt) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            if param.FP16:\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(opt), 1)\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(mdl.parameters(), 1)\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            prdtr_ep.append(prdb.cpu().detach().numpy())\n",
    "            ytr_ep.append(yb.cpu().detach().numpy())\n",
    "            if step>0 and step%1000==0: print(dtnow(), f'ep {epc} step {step}/{lendl}')\n",
    "\n",
    "        prdtr_ep = np.concatenate(prdtr_ep)\n",
    "        ytr_ep = np.concatenate(ytr_ep)    \n",
    "        lss_tr_ep = F.binary_cross_entropy_with_logits(torch.tensor(prdtr_ep),torch.tensor(ytr_ep)).item()\n",
    "        scr_tr_ep = roc_auc(ytr_ep>=0.5, prdtr_ep)\n",
    "        stats['lss']['tr'].append(lss_tr_ep)\n",
    "        stats['scr']['tr'].append(scr_tr_ep)\n",
    "\n",
    "        lss_vl_ep, scr_vl_ep, yvl_ep, prdvl_ep = evaluate(mdl, dlvl)\n",
    "        stats['lss']['vl'].append(lss_vl_ep)\n",
    "        stats['scr']['vl'].append(scr_vl_ep)\n",
    "        ep2oof.append(prdvl_ep)\n",
    "\n",
    "        lss_vl20_ep, scr_vl20_ep, yvl20_ep, prdvl20_ep = evaluate(mdl, dlvl20)\n",
    "        stats['lss']['vl20'].append(lss_vl20_ep)\n",
    "        stats['scr']['vl20'].append(scr_vl20_ep)\n",
    "\n",
    "        print(dtnow(), f'fld {fld} ep {epc}: lss_tr {lss_tr_ep:.3f}; lss_vl {lss_vl_ep:.3f}; lss_vl20 {lss_vl20_ep:.3f}; scr_tr {scr_tr_ep:.3f}; scr_vl {scr_vl_ep:.3f}; scr_vl20 {scr_vl20_ep:.3f}; ')\n",
    "\n",
    "        if epc> (5 if not param.DEBUG else -1):\n",
    "            prdtst = infer(mdl, dltst)\n",
    "            dfsub.target = sigmoid(prdtst)\n",
    "            dfsub.to_csv(f'{p_out}/submission_{param.PRFX}_fld_{fld}_epc_{epc}.csv', index=False)\n",
    "            torch.save(mdl.state_dict(), f'{p_out}/model_{param.PRFX}_fld_{fld}_epc_{epc}.p')\n",
    "\n",
    "        if scr_vl_ep>best_scr:\n",
    "            print(f'better scr {best_scr:.3f} -> {scr_vl_ep:.3f}')\n",
    "            best_scr = scr_vl_ep\n",
    "            best_epc = epc\n",
    "            torch.save(mdl.state_dict(), f'{p_out}/model_{param.PRFX}_fld_{fld}_best.p')\n",
    "            dfsub.to_csv(f'{p_out}/submission_{param.PRFX}_fld_{fld}_best.csv', index=False)\n",
    "\n",
    "        if scr_vl20_ep>best_scr20:\n",
    "            print(f'better scr20 {best_scr20:.3f} -> {scr_vl20_ep:.3f}')\n",
    "            best_scr20 = scr_vl20_ep\n",
    "            best_epc20 = epc\n",
    "            torch.save(mdl.state_dict(), f'{p_out}/model_{param.PRFX}_fld_{fld}_best20.p')\n",
    "            dfsub.to_csv(f'{p_out}/submission_{param.PRFX}_fld_{fld}_best20.csv', index=False)\n",
    "\n",
    "        schdl.step(scr_vl_ep)  # Update learning rate schedule\n",
    "        \n",
    "        stats['best_scr'] = best_scr\n",
    "        stats['best_epc'] = best_epc\n",
    "        stats['best_scr20'] = best_scr20\n",
    "        stats['best_epc20'] = best_epc20\n",
    "        results['fld2stats'][fld] = stats\n",
    "        pickle.dump(results, open(f'{p_out}/results_{param.PRFX}.p', 'wb'))  \n",
    "    pickle.dump(ep2oof, open(f'{p_out}/ep2oof_{param.PRFX}_fld_{fld}.p', 'wb'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results, open(f'{p_out}/results_{param.PRFX}.p', 'wb'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training trajec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mtrc in ['lss', 'scr']:\n",
    "    for k in ['tr','vl','vl20']:\n",
    "        plt.title(f'{mtrc} {k}')\n",
    "        for fld in param.FLDS2USE:\n",
    "            plt.plot(results['fld2stats'][fld][mtrc][k], 'o--')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vls = []\n",
    "for fld in param.FLDS2USE:\n",
    "    _,vl=fld2trvl[fld]\n",
    "    vls += list(vl)\n",
    "len(vls), vls[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only last epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs = []\n",
    "for fld in param.FLDS2USE:\n",
    "    ep2oof = pickle.load(open(f'{p_out}/ep2oof_{param.PRFX}_fld_{fld}.p', 'rb'))\n",
    "    ep2oof = np.concatenate(ep2oof,1)\n",
    "    oof = list(ep2oof[:,-1])\n",
    "    oofs += list(oof)\n",
    "    \n",
    "roc_auc(dftrn.target.iloc[vls], oofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_sorted = np.array([o[1] for o in sorted(zip(vls,oofs))])\n",
    "roc_auc(dftrn.target.iloc[idx20], oof_sorted[idx20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only best_scr epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs = []\n",
    "for fld in param.FLDS2USE:\n",
    "    ep2oof = pickle.load(open(f'{p_out}/ep2oof_{param.PRFX}_fld_{fld}.p', 'rb'))\n",
    "    ep2oof = np.concatenate(ep2oof,1)\n",
    "    best_epc = results['fld2stats'][fld]['best_epc']\n",
    "    oof = list(ep2oof[:,best_epc])\n",
    "    oofs += list(oof)\n",
    "roc_auc(dftrn.target.iloc[vls], oofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_sorted = np.array([o[1] for o in sorted(zip(vls,oofs))])\n",
    "roc_auc(dftrn.target.iloc[idx20], oof_sorted[idx20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only best_scr20 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs = []\n",
    "for fld in param.FLDS2USE:\n",
    "    ep2oof = pickle.load(open(f'{p_out}/ep2oof_{param.PRFX}_fld_{fld}.p', 'rb'))\n",
    "    ep2oof = np.concatenate(ep2oof,1)\n",
    "    best_epc = results['fld2stats'][fld]['best_epc20']\n",
    "    oof = list(ep2oof[:,best_epc])\n",
    "    oofs += list(oof)\n",
    "roc_auc(dftrn.target.iloc[vls], oofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_sorted = np.array([o[1] for o in sorted(zip(vls,oofs))])\n",
    "roc_auc(dftrn.target.iloc[idx20], oof_sorted[idx20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avg all epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs = []\n",
    "for fld in param.FLDS2USE:\n",
    "    ep2oof = pickle.load(open(f'{p_out}/ep2oof_{param.PRFX}_fld_{fld}.p', 'rb'))\n",
    "    ep2oof = np.concatenate(ep2oof,1)\n",
    "    oof = list(ep2oof.mean(1))\n",
    "    oofs += list(oof)\n",
    "roc_auc(dftrn.target.iloc[vls], oofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_sorted = np.array([o[1] for o in sorted(zip(vls,oofs))])\n",
    "roc_auc(dftrn.target.iloc[idx20], oof_sorted[idx20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avg last m epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs = []\n",
    "for fld in param.FLDS2USE:\n",
    "    ep2oof = pickle.load(open(f'{p_out}/ep2oof_{param.PRFX}_fld_{fld}.p', 'rb'))\n",
    "    ep2oof = np.concatenate(ep2oof,1)\n",
    "    oof = list(ep2oof[:, -3:].mean(1))\n",
    "    oofs += list(oof)\n",
    "roc_auc(dftrn.target.iloc[vls], oofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_sorted = np.array([o[1] for o in sorted(zip(vls,oofs))])\n",
    "roc_auc(dftrn.target.iloc[idx20], oof_sorted[idx20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_avg_last_m(m):\n",
    "    oofs = []\n",
    "    for fld in param.FLDS2USE:\n",
    "        ep2oof = pickle.load(open(f'{p_out}/ep2oof_{param.PRFX}_fld_{fld}.p', 'rb'))\n",
    "        ep2oof = np.concatenate(ep2oof,1)\n",
    "        oof = list(ep2oof[:, -m:].mean(1))\n",
    "        oofs += list(oof)\n",
    "    return oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(1, 5):\n",
    "    oofs = get_oof_avg_last_m(m)\n",
    "    oof_sorted = np.array([o[1] for o in sorted(zip(vls,oofs))])\n",
    "    print(m, f'{roc_auc(dftrn.target.iloc[vls], oofs):.3f}', \n",
    "          f'{roc_auc(dftrn.target.iloc[idx20], oof_sorted[idx20]):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avg last m epochs before epo-q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_avg_last_m_before_q(m,q):\n",
    "    oofs = []\n",
    "    for fld in param.FLDS2USE:\n",
    "        ep2oof = pickle.load(open(f'{p_out}/ep2oof_{param.PRFX}_fld_{fld}.p', 'rb'))\n",
    "        ep2oof = np.concatenate(ep2oof,1)\n",
    "        oof = list(ep2oof[:, q-m:q].mean(1))\n",
    "        oofs += list(oof)\n",
    "    return oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(1, 5):\n",
    "    oofs = get_oof_avg_last_m_before_q(m, 10)\n",
    "    oof_sorted = np.array([o[1] for o in sorted(zip(vls,oofs))])\n",
    "    print(m, f'{roc_auc(dftrn.target.iloc[vls], oofs):.3f}', \n",
    "          f'{roc_auc(dftrn.target.iloc[idx20], oof_sorted[idx20]):.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_sub = []\n",
    "for fld in param.FLDS2USE:\n",
    "    sub_fld = pd.read_csv(f'{p_out}/submission_{param.PRFX}_fld_{fld}_epc_{param.EPOCHS-1}.csv') \n",
    "    print('fld', fld, sub_fld.target.mean())\n",
    "    display(sub_fld.head(3))\n",
    "    lst_sub.append(sub_fld.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.mean(lst_sub,0)\n",
    "print(sub.mean())\n",
    "dfsub.target = sub\n",
    "display(dfsub.head(3))\n",
    "plt.hist(dfsub.target, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub.to_csv(f'{p_out}/submission_{param.PRFX}_onlylast.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only best_scr epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_sub = []\n",
    "for fld in param.FLDS2USE:\n",
    "    sub_fld = pd.read_csv(f'{p_out}/submission_{param.PRFX}_fld_{fld}_best.csv') \n",
    "    print('fld', fld, sub_fld.target.mean())\n",
    "    display(sub_fld.head(3))\n",
    "    lst_sub.append(sub_fld.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.mean(lst_sub,0)\n",
    "print(sub.mean())\n",
    "dfsub.target = sub\n",
    "display(dfsub.head(3))\n",
    "plt.hist(dfsub.target, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub.to_csv(f'{p_out}/submission_{param.PRFX}_onlybestscr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only best_scr20 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_sub = []\n",
    "for fld in param.FLDS2USE:\n",
    "    sub_fld = pd.read_csv(f'{p_out}/submission_{param.PRFX}_fld_{fld}_best20.csv') \n",
    "    print('fld', fld, sub_fld.target.mean())\n",
    "    display(sub_fld.head(3))\n",
    "    lst_sub.append(sub_fld.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.mean(lst_sub,0)\n",
    "print(sub.mean())\n",
    "dfsub.target = sub\n",
    "display(dfsub.head(3))\n",
    "plt.hist(dfsub.target, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub.to_csv(f'{p_out}/submission_{param.PRFX}_onlybestscr20.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avg last m epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_sub = []\n",
    "for fld in param.FLDS2USE:\n",
    "    for epc in range(param.EPOCHS-m, param.EPOCHS):\n",
    "        sub_fld = pd.read_csv(f'{p_out}/submission_{param.PRFX}_fld_{fld}_epc_{epc}.csv') \n",
    "        print('fld', fld, 'epc', epc, sub_fld.target.mean())\n",
    "        display(sub_fld.head(3))\n",
    "        lst_sub.append(sub_fld.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub = np.mean(lst_sub,0)\n",
    "print(sub.mean())\n",
    "dfsub.target = sub\n",
    "display(dfsub.head(3))\n",
    "plt.hist(dfsub.target, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub.to_csv(f'{p_out}/submission_{param.PRFX}_avglast{m}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avg last m epochs before epo-q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "q = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_sub = []\n",
    "for fld in param.FLDS2USE:\n",
    "    for epc in range(q-m, q):\n",
    "        sub_fld = pd.read_csv(f'{p_out}/submission_{param.PRFX}_fld_{fld}_epc_{epc}.csv') \n",
    "        print('fld', fld, 'epc', epc, sub_fld.target.mean())\n",
    "        display(sub_fld.head(3))\n",
    "        lst_sub.append(sub_fld.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub = np.mean(lst_sub,0)\n",
    "print(sub.mean())\n",
    "dfsub.target = sub\n",
    "display(dfsub.head(3))\n",
    "plt.hist(dfsub.target, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsub.to_csv(f'{p_out}/submission_{param.PRFX}_{m}before{q}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mel",
   "language": "python",
   "name": "mel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
